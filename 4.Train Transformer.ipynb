{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4023a333-7aa9-4f0c-ad86-2bee471c586f",
   "metadata": {},
   "source": [
    "### Train Transformer\n",
    "\n",
    "Paper: https://pubs.rsna.org/doi/suppl/10.1148/ryai.210174 \n",
    "\n",
    "Code: https://github.com/tarakapoor/thyroid_deep_learning\n",
    "\n",
    "Dataset: https://stanfordaimi.azurewebsites.net/datasets/a72f2b02-7b53-4c5d-963c-d7253220bfd5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f164ef-89b9-4e79-a368-af3d37f75395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#req\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import tables\n",
    "import cv2\n",
    "import h5py\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "\n",
    "#data aug\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "#from albumentations.pytorch import ToTensor\n",
    "import albumentations as A\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, f1_score\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import h5py\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4804da2-fa4c-4640-9361-b76ee9f1ae8e",
   "metadata": {},
   "source": [
    "## Define Transformer (transformer_model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dcbd06-3ce4-4dfd-99e2-f76afea895e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from os import path\n",
    "import operator\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from torch import Tensor\n",
    "import time\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "\n",
    "#https://github.com/pytorch/pytorch/issues/24826\n",
    "class PositionalEncoder(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len=72):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_seq_len, d_model) #36, 256\n",
    "        for pos in range(max_seq_len): #in range 36 (each patient feature vector)\n",
    "            for i in range(0, d_model, 2): #in range [256] within feature vector\n",
    "                pe[pos, i] = \\\n",
    "                    math.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                    math.cos(pos / (10000 ** ((2 * (i + 1)) / d_model)))\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = x * math.sqrt(self.d_model)\n",
    "            seq_len = x.size(1)\n",
    "            pe = self.pe[:, :seq_len]\n",
    "            x = x + pe\n",
    "            return x\n",
    "        \n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self,in_size,use_position_enc,\n",
    "                 n_heads=2,\n",
    "                 n_encoders=2,\n",
    "                 num_outputs=2,\n",
    "                ):\n",
    "        \"\"\"Custom Transformer Model class with encoder.\n",
    "        Keyword arguments:\n",
    "        in_size -- number of features in one frame's feature vector\n",
    "        use_position_enc -- whether to use positional encoding\n",
    "        n_heads -- number of (self-attention + feed forward) heads in an encoder\n",
    "        n_encoders -- number of encoders\n",
    "        num_outputs -- number of output classes (binary 0 or 1 means 2 output classes)\"\"\"\n",
    "        \n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.in_size=in_size\n",
    "        self.use_position_enc = use_position_enc #positional encoding or not?\n",
    "        \n",
    "        self.encoder_layer =nn.TransformerEncoderLayer(in_size, \n",
    "                                                       n_heads,)\n",
    "        \n",
    "        self.encoder=nn.TransformerEncoder(self.encoder_layer, n_encoders)\n",
    "#        self.decoder=nn.TransformerDecoder(self.decoder_layer, 2)\n",
    "\n",
    "        print(\"transformer in size\", self.in_size)\n",
    "\n",
    "        self.classifier = nn.Linear(in_size, num_outputs)\n",
    "        self.pos_embd=PositionalEncoder(in_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function for Transformer Model.\n",
    "        Reshapes input to encoder input (S, N, E) : S = sequence or # frame feature vectors fed in from patient (36), N = batch size (1), E = # of features (in_size, 256)\"\"\"\n",
    "        x = x.permute(1, 0, 2) #now [S, 1, 256]\n",
    "        \n",
    "        if(self.use_position_enc): #positional encoding choice\n",
    "            x = self.pos_embd(x)\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f3a95-ef92-4613-a95e-547ca830a42b",
   "metadata": {},
   "source": [
    "**data transforms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dafaf72-f723-434e-8aae-eae1c6b4eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(col):\n",
    "    \"\"\"NORMALIZE 2D FEATURES from CSV file (manually extracted).\n",
    "    Add minimum value to all feature values to make minimum 0, then normalize so all feature values between 0 and 1.\n",
    "    Input is column of feature values (1 feature value per frame) for a given feature, output is normalized column of feature values.\"\"\"\n",
    "\n",
    "    minfeat = np.nanmin(col)\n",
    "    if(minfeat < 0):\n",
    "        for row in range(len(col)):\n",
    "            col[row] = col[row] + (-1*minfeat)\n",
    "    #min feature should now be 0 (no negatives)\n",
    "    \n",
    "    maxfeat = np.nanmax(col)\n",
    "    if(maxfeat != 0):\n",
    "        for row in range(len(col)):\n",
    "            if(math.isnan(col[row])):\n",
    "                col[row] = 0.0\n",
    "            col[row] = (col[row]/maxfeat)\n",
    "    return col    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb196d6-2eb2-41c6-8433-6b7d9cb803d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process2dfeatures(vertconcat, cvphase, features2dpath, phase):\n",
    "    \"\"\"Extract manual 2d features, normalize features by column.\n",
    "    Keyword arguments:\n",
    "    vertconcat -- whether to vertically concatenate (true) or horizontally concatenate (false) manual 2d features.\n",
    "    cvphase -- cross validation fold (0 to 4)\n",
    "    features2dpath -- path to manual 2d features.\n",
    "    Return lists of feature vectors by frame, label, patient ID and frame number within patient.\"\"\"\n",
    "\n",
    "    if(vertconcat):\n",
    "        featurelength = 256\n",
    "    else:\n",
    "        featurelength = 256\n",
    "    cur_all_concats = np.zeros((0,256)) #reset to empty\n",
    "    concatpats = []\n",
    "    concatlabs = []\n",
    "    concatframenums = []\n",
    "    \n",
    "    if(phase == \"train\"):\n",
    "        if(cvphase == 0):\n",
    "            curfold = 3\n",
    "        elif(cvphase == 1):\n",
    "            curfold = 4\n",
    "        else:\n",
    "            curfold = cvphase - 2\n",
    "    elif(phase == \"val\"):\n",
    "        if(cvphase == 4):\n",
    "            curfold = 0\n",
    "        else:\n",
    "            curfold = cvphase + 1\n",
    "    elif(phase == \"test\"):\n",
    "        curfold = cvphase\n",
    "    elif(phase == \"trainval\"):\n",
    "        if(cvphase == 0):\n",
    "            curfold = 3\n",
    "        elif(cvphase == 1):\n",
    "            curfold = 4\n",
    "        else:\n",
    "            curfold = cvphase - 2\n",
    "\n",
    "    rowcount = 0\n",
    "    #numberind = 0\n",
    "    with open(features2dpath, newline='') as infh:\n",
    "        print(\"opened csv to concatenate manual features\")\n",
    "        reader = csv.reader(infh)\n",
    "        rowcount = 0\n",
    "\n",
    "        mypats = []\n",
    "        curstartsubtract = 0\n",
    "        curind = 1\n",
    "        for row in reader:\n",
    "            if(row[2] != '0' and row[2] != '1'):\n",
    "                print(\"error col label:\", row[2])\n",
    "                continue\n",
    "\n",
    "            #numberind = (row[0].index('_'))+1\n",
    "            curpatindexfull = row[0]\n",
    "            concatpats.append(row[1])\n",
    "            if(row[1] not in mypats):\n",
    "                mypats.append(row[1])\n",
    "                curind = 1 #first framenum, renumber\n",
    "            concatframenums.append(curind)#(curpatindexfull[numberind:])\n",
    "            concatlabs.append(row[2])\n",
    "\n",
    "            concats = np.array(row[3:], dtype=float)\n",
    "            #extrapad = np.zeros((1, featurelength-256))\n",
    "            if(vertconcat):\n",
    "                if(len(concats)<featurelength):\n",
    "                    concats = np.append(concats, extrapad) #pad to 256\n",
    "            \n",
    "            cur_all_concats = np.vstack((cur_all_concats, concats)) #should have length 256\n",
    "            if(rowcount % 5000 == 0):\n",
    "                print(\"row:\", rowcount, \"curind\", curind)\n",
    "            #end loop, now new loop\n",
    "            rowcount += 1\n",
    "            curind += 1 #framenum\n",
    "        print(\"rowcount\", rowcount)\n",
    "\n",
    "    #loop through columns and normalize\n",
    "    for colnum in range(len(cur_all_concats[0])):\n",
    "        cur_all_concats[:, colnum] = normalize(cur_all_concats[:, colnum])\n",
    "        \n",
    "    return cur_all_concats, concatpats, concatlabs, concatframenums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4315029-bfc9-4b6a-91c0-9e57d01452f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_padded_transformer_horiz_concat(phase, cvphase, frametype, project_home_dir, features2dpath):\n",
    "    \"\"\"Extract features from CNN csv file for given phase and cvphase, stack based on frametype.\n",
    "    Manual 2d features concatenated horizontally here (102 added to 256 features to have 358 per frame feature vector).\n",
    "    Keyword arguments:\n",
    "    phase -- train, val, trainval or test (which data to use)\n",
    "    cvphase -- cross validation fold (0 to 4)\n",
    "    frametype -- adjacent, equalspaced or singleframe (whether to stack frames or not, and how if so)\n",
    "    Return (for given cross validation fold and train/val/trainval/test phase) lists of all feature vectors, labels, patient IDs and frame numbers within patient.\"\"\"\n",
    "    foundcount = 0\n",
    "    \n",
    "    trainvalfile = features2dpath\n",
    "    filename = trainvalfile\n",
    "    \n",
    "    curfold = 0\n",
    "    print(\"CVPHASE:\", cvphase, \"\\ncsv:\", filename)\n",
    "    if(phase == \"train\"):\n",
    "        curfile = filename\n",
    "        if(cvphase == 0):\n",
    "            curfold = 3\n",
    "        elif(cvphase == 1):\n",
    "            curfold = 4\n",
    "        else:\n",
    "            curfold = cvphase - 2\n",
    "    elif(phase == \"val\"):\n",
    "        curfile = valfile\n",
    "        if(cvphase == 4):\n",
    "            curfold = 0\n",
    "        else:\n",
    "            curfold = cvphase + 1\n",
    "    elif(phase == \"test\"):\n",
    "        curfile = testfile\n",
    "        curfold = cvphase\n",
    "    elif(phase == \"trainval\"):\n",
    "        curfile = trainvalfile\n",
    "        if(cvphase == 0):\n",
    "            curfold = 3\n",
    "        elif(cvphase == 1):\n",
    "            curfold = 4\n",
    "        else:\n",
    "            curfold = cvphase - 2\n",
    "    \n",
    "    featurelength = 256+102\n",
    "        \n",
    "    cur_all_pat_inds = []\n",
    "    cur_all_patients = []\n",
    "    cur_all_labels = []\n",
    "    cur_all_probs = np.zeros((0,featurelength))\n",
    "    \n",
    "    #col 0 = framenum, col 1 = patient id, col 2 = label, rest = probabilities\n",
    "    rowcount = 0\n",
    "    with open(curfile, newline='') as infh:\n",
    "        print(\"opened csv for cnn features\")\n",
    "        reader = csv.reader(infh)\n",
    "        rowcount = 0\n",
    "        for row in reader:\n",
    "            if(row[3] == ''):\n",
    "                print(\"ERROR\", row[2])\n",
    "                continue\n",
    "            cur_all_pat_inds.append(row[0])\n",
    "            cur_all_labels.append(row[2])\n",
    "            cur_all_patients.append(row[1])\n",
    "            probs = np.array(row[3:], dtype=float)\n",
    "            probs = np.append(probs, np.zeros((102)))\n",
    "            \n",
    "            if(rowcount % 500 == 0):\n",
    "                print(\"row:\", rowcount)\n",
    "            \n",
    "            cur_all_probs = np.vstack((cur_all_probs, probs))\n",
    "            rowcount += 1\n",
    "        print(\"rowcount\", rowcount)\n",
    "            \n",
    "    print(\"length of probs, labels, ids\", len(cur_all_probs), len(cur_all_labels), len(cur_all_patients))\n",
    "    \n",
    "    #get number of images per patient\n",
    "    distinct_patient_ids = []\n",
    "    distinct_num_pats = []\n",
    "    \n",
    "    #SORT IN ORDER OF FRAME NUM NOW, BEFORE PADDING!\n",
    "    cur_all_pat_inds = np.array(cur_all_pat_inds).astype(np.float64)\n",
    "    print(\"type of cur_all_pat_inds\", type(cur_all_pat_inds))\n",
    "    templist = list(zip(cur_all_patients, cur_all_pat_inds, cur_all_probs, cur_all_labels))\n",
    "    sortedlist = sorted(templist, key=operator.itemgetter(0, 1))\n",
    "    cur_all_patients, cur_all_pat_inds, cur_all_probs, cur_all_labels = zip(*sortedlist)\n",
    "    print(\"\\n\\n\\n should be sorted (framenums, patient id, label):\", cur_all_pat_inds[0:10], cur_all_patients[0:10], cur_all_labels[0:10])\n",
    "    \n",
    "    print(\"\\n\\nLOADING\", phase,\"PHASE\")\n",
    "    maxpat = \"\"\n",
    "    maxpatcount = 0\n",
    "    curpatcount = 0\n",
    "    \n",
    "    for patt in cur_all_patients:\n",
    "        if (patt not in distinct_patient_ids):\n",
    "            curpatcount = 0\n",
    "            distinct_patient_ids.append(patt)\n",
    "            for xz in range(len(cur_all_patients)):                \n",
    "                if(cur_all_patients[xz] == patt):\n",
    "                    curpatcount += 1\n",
    "                    if(curpatcount >= maxpatcount):\n",
    "                        maxpat = patt\n",
    "                        maxpatcount = curpatcount\n",
    "                        \n",
    "            distinct_num_pats.append(curpatcount)\n",
    "            print(\"patient\", patt, \": CNN extracted # of frames =\", curpatcount)\n",
    "    \n",
    "    print(\"cur all probs shape\", np.shape(cur_all_probs))\n",
    "    print(\"num patients:\", len(distinct_patient_ids), \" total length:\", len(cur_all_patients))\n",
    "    \n",
    "\n",
    "    cur_all_concats, _, _, _ = process2dfeatures(False, cvphase, features2dpath, \"train\")\n",
    "    _, concatpats, concatlabs, concatframenums = cur_all_probs, cur_all_patients, cur_all_labels, cur_all_pat_inds\n",
    "\n",
    "\n",
    "    #need to now add to probs the next two rows and then average before the for loop\n",
    "    #THIS IS FOR ADJACENT FRAMES!\n",
    "    print(\"from concat features: pats\", concatpats[int(len(concatpats)/3)])\n",
    "\n",
    "    for looppats in range(len(cur_all_patients)): #every single index of each individual feature vector instance. should be thousands\n",
    "        if(looppats % 1000 == 0):\n",
    "            print(\"looping through all feature vectors, index\", looppats)\n",
    "        thecurpat = cur_all_patients[looppats]\n",
    "        thecurframenum = cur_all_pat_inds[looppats]\n",
    "\n",
    "        patientind = concatpats.index(thecurpat) #find first instance of this patient in concat patient list\n",
    "        lastpatientind = len(concatpats) - 1 - concatpats[::-1].index(thecurpat) #find last instance of this patient in patient list\n",
    "\n",
    "        avgfeatures = np.zeros((3,256))\n",
    "        found = False\n",
    "        for gg in range(patientind, lastpatientind):\n",
    "            avgfeatures = np.zeros((3,256))\n",
    "\n",
    "            if(int(cur_all_pat_inds[looppats]) == int(concatframenums[gg])): #corresponding first frame #\n",
    "                if(gg>=(len(cur_all_concats)-2)):\n",
    "                    print(\"over limit; gg, features\", gg, \"len avg features and concats\", len(avgfeatures), len(cur_all_concats[gg]))\n",
    "                    gg-=2\n",
    "                foundcount += 1\n",
    "                found = True\n",
    "                avgfeatures[0] = cur_all_concats[gg]#1st row of concat probs\n",
    "                avgfeatures[1] = cur_all_concats[gg+1]#add 2nd row of concat probs\n",
    "                avgfeatures[2] = cur_all_concats[gg+2]#add 3rd row of concat probs\n",
    "\n",
    "                avgfeatures = np.average(avgfeatures, axis=0)\n",
    "                avgfeatures = np.array(avgfeatures)\n",
    "                print(avgfeatures.shape)\n",
    "                cur_all_probs[looppats][-256:] = avgfeatures\n",
    "\n",
    "        patienttot = len(cur_all_patients) - 1 - cur_all_patients[::-1].index(thecurpat) - cur_all_patients.index(thecurpat)\n",
    "        if(not found):\n",
    "            print(\"framenum notmatching\", thecurpat, \"cnn framenum:\", cur_all_pat_inds[looppats], \"vs.\", concatframenums[patientind], \"to\", concatframenums[lastpatientind])#:lastpatientind])\n",
    "\n",
    "        \"\"\"#below is for appending first frame's features, not average of 3 stacked frames\n",
    "        for gg in range(patientind, lastpatientind):\n",
    "            if(cur_all_pat_inds[gg] == curpatindexfull[numberind:]):\n",
    "                cur_all_probs[gg][256:] = probs #np.vstack((cur_all_probs, probs))#np.stack((cur_all_probs, probs))\n",
    "                #print(\"ERROR SHAPE IS WRONG!!! in row\", rowcount, len(cur_all_probs[gg][256:]), \"vs. len probs\", len(probs))\n",
    "        \"\"\"\n",
    "    print(\"\\n\\nFOUND total of\", foundcount,\"corresponding 2d features vs. total of\", len(cur_all_probs), \"frames\")\n",
    "\n",
    "    tempp = list(zip(distinct_num_pats, distinct_patient_ids)) \n",
    "    tempp = sorted(tempp) \n",
    "    distinct_num_pats, distinct_patient_ids = zip(*tempp)\n",
    "    \n",
    "    print(phase, \"PATIENTS:\", distinct_patient_ids)\n",
    "    print(\"cvphase\", cvphase,\"numpatients input:\", len(distinct_patient_ids))\n",
    "    \n",
    "    curpatprobs = np.zeros((0,featurelength))\n",
    "    curpatlabs = []\n",
    "    curpatids = []\n",
    "    curpatframenums = []\n",
    "    \n",
    "    allfeatures = np.zeros((0, featurelength))\n",
    "    alllabels = []\n",
    "    allids = []\n",
    "    allframenums = []\n",
    "    \n",
    "    #ADD INDIVIDUAL PATIENT VECTORS TO ALLFEATURES VECTOR\n",
    "    #pad and stack\n",
    "    counttt = 0\n",
    "    seq_len = 36\n",
    "\n",
    "    for patind in range(len(distinct_patient_ids)):\n",
    "        curpatprobs = np.zeros((0,featurelength))\n",
    "        curpatlabs = []\n",
    "        curpatids = []\n",
    "        curpatframenums = []\n",
    "        \n",
    "        pat = distinct_patient_ids[patind]\n",
    "        for p in range(len(cur_all_patients)):\n",
    "            if (cur_all_patients[p] == pat):\n",
    "                curprobs = cur_all_probs[p]\n",
    "                curprobs = curprobs.reshape((1,featurelength))\n",
    "                curlabels = cur_all_labels[p]\n",
    "                curids = cur_all_patients[p]\n",
    "                curframenums = cur_all_pat_inds[p]\n",
    "                \n",
    "                curpatprobs = np.concatenate((curpatprobs, curprobs), axis=0)\n",
    "                curpatlabs = np.append(curpatlabs, curlabels)\n",
    "                curpatids = np.append(curpatids, curids)\n",
    "                curpatframenums = np.append(curpatframenums, curframenums)\n",
    "        \n",
    "        \n",
    "        numimgs = len(curpatprobs)\n",
    "        goodlenprobs = np.zeros((seq_len,featurelength))\n",
    "        #PAD NOW\n",
    "        if (numimgs > seq_len):\n",
    "            num_seqs = 1\n",
    "            lencurseq = 36\n",
    "            while((numimgs / num_seqs) > seq_len):\n",
    "                num_seqs += 1\n",
    "            \n",
    "            lencurseq = numimgs / num_seqs\n",
    "            \n",
    "            for g in range(num_seqs):\n",
    "                #split into groups of less than 36 vectors of length 256\n",
    "                start = int(g*lencurseq)\n",
    "                end = int(((g+1)*lencurseq))\n",
    "                if(g<(num_seqs)-1):\n",
    "                    currentseq = curpatprobs[start:end]\n",
    "                    currentlabs = curpatlabs[start:end]\n",
    "                    currentids = curpatids[start:end]\n",
    "                    currentframes = curpatframenums[start:end]\n",
    "                else:\n",
    "                    currentseq = curpatprobs[start:]\n",
    "                    currentlabs = curpatlabs[start:]\n",
    "                    currentids = curpatids[start:]\n",
    "                    currentframes = curpatframenums[start:]\n",
    "                    \n",
    "                #pad each to 36\n",
    "                currentseq = torch.nn.utils.rnn.pad_sequence([torch.from_numpy(currentseq), torch.from_numpy(goodlenprobs)], batch_first=True, padding_value=0.0)\n",
    "                currentseq = np.array(currentseq[0])\n",
    "                while(len(currentlabs)<seq_len):\n",
    "                    currentlabs = np.append(currentlabs, currentlabs[0]) #or just '0'?\n",
    "                    currentids = np.append(currentids, currentids[0])\n",
    "                    currentframes = np.append(currentframes, 0)\n",
    "                if((g==0) and (patind == 0)):\n",
    "                    print(\"shape of padded sequence, labels, ids:\", np.shape(currentseq), np.shape(currentlabs), np.shape(currentids), np.shape(currentframes))\n",
    "                \n",
    "                #add 36 at a time from curpat probs to allfeatures\n",
    "                allfeatures = np.concatenate((allfeatures, currentseq), axis=0)\n",
    "                alllabels = np.append(alllabels, currentlabs)\n",
    "                allids = np.append(allids, currentids)\n",
    "                allframenums = np.append(allframenums, currentframes)\n",
    "            \n",
    "        elif (numimgs < seq_len):\n",
    "            #just pad to 36\n",
    "            diff = seq_len-len(curpatprobs)\n",
    "            while(len(curpatlabs)<seq_len):\n",
    "                curpatlabs = np.append(curpatlabs, curpatlabs[0])\n",
    "                curpatids = np.append(curpatids, curpatids[0])\n",
    "                curpatframenums = np.append(curpatframenums, curpatframenums[0])#0)\n",
    "\n",
    "            currentseq = torch.nn.utils.rnn.pad_sequence([torch.from_numpy(curpatprobs), torch.from_numpy(goodlenprobs)], batch_first=True, padding_value=0.0)\n",
    "            currentseq = np.array(currentseq[0])\n",
    "            \n",
    "            #add the 36 from curpatprobs to allfeatures\n",
    "            allfeatures = np.concatenate((allfeatures, currentseq), axis=0)\n",
    "            alllabels = np.append(alllabels, curpatlabs)\n",
    "            allids = np.append(allids, curpatids)\n",
    "            allframenums = np.append(allframenums, curpatframenums)\n",
    "\n",
    "        else:\n",
    "            allfeatures = np.concatenate((allfeatures, curpatprobs), axis=0)\n",
    "            alllabels = np.append(alllabels, curpatlabs)\n",
    "            allids = np.append(allids, curpatids)\n",
    "            allframenums = np.append(allframenums, curpatframenums)\n",
    "        \n",
    "        counttt+= 1\n",
    "        \n",
    "    print(\"example features:\\n\", allfeatures[0][0], allfeatures[0][256], allfeatures[0][300])\n",
    "    print(\"\\nFINAL features, labels, ids shapes\", np.shape(allfeatures), np.shape(alllabels), np.shape(allids), np.shape(allframenums))\n",
    "    return(allfeatures, alllabels, allids, allframenums) #return feature vectors and labels and patient ids for transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b290187-1b44-4827-9ad6-66f0652b7e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_embeddings_ALL_IMAGES.csv  ViT_embeddings_FOLD0.csv\n",
      "mobilenet_embeddings_FOLD0.csv\t     ViT_embeddings_FOLD1.csv\n",
      "mobilenet_embeddings_FOLD1.csv\t     ViT_embeddings_FOLD2.csv\n",
      "mobilenet_embeddings_FOLD2.csv\t     ViT_embeddings_FOLD3.csv\n",
      "mobilenet_embeddings_FOLD3.csv\t     ViT_embeddings_FOLD4.csv\n",
      "mobilenet_embeddings_FOLD4.csv\n"
     ]
    }
   ],
   "source": [
    "!ls backbone_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65fb93ef-f0b2-4073-9a42-434ae61f89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetPaddedTransformer(data.Dataset):\n",
    "    def __init__(self, phase, cvphase, concat_features, vertconcat, frametype, project_home_dir, all):\n",
    "        \"\"\"Data loader for Transformer Model.\"\"\"\n",
    "        super(DatasetPaddedTransformer, self).__init__()\n",
    "        \n",
    "        if all == False:\n",
    "            features2dpath = \"backbone_embeddings/mobilenet_embeddings_FOLD%s.csv\" % cvphase\n",
    "        else:\n",
    "            features2dpath = \"backbone_embeddings/mobilenet_embeddings_ALL_IMAGES.csv\"\n",
    "            \n",
    "\n",
    "        self.phase = phase\n",
    "        if(True): #horizontal concat or vertical concatenated 2d features\n",
    "            if(vertconcat):\n",
    "                self.all_frames, self.all_labels, self.all_annot_ids, self.all_frame_nums = load_csv_padded_transformer_vertical_concat(phase, cvphase, frametype, project_home_dir, features2dpath)\n",
    "            else:\n",
    "                self.all_frames, self.all_labels, self.all_annot_ids, self.all_frame_nums = load_csv_padded_transformer_horiz_concat(phase, cvphase, frametype, project_home_dir, features2dpath)\n",
    "        else: #no concatenated 2d features\n",
    "            self.all_frames, self.all_labels, self.all_annot_ids, self.all_frame_nums = load_csv_padded_transformer(phase, cvphase, frametype, project_home_dir)\n",
    "                \n",
    "        self.seqlength = 36\n",
    "        self.start_indices = []\n",
    "        numiters = len(self.all_frames) / self.seqlength\n",
    "        print(\"numiters\", numiters)\n",
    "        for x in range(int(numiters)):\n",
    "            self.start_indices.append(x*self.seqlength)\n",
    "        print(\"done reading in images and labels for\", phase, \"!!!\\n\\n\")\n",
    "        print(\"start indices (should be multiples of sequence length only):\", self.start_indices)\n",
    "        print(\"all frames:\", len(self.all_frames), np.shape(self.all_frames))\n",
    "    \n",
    "    \n",
    "    #getitem is called 'batch_size' number of times in one iteration of the epoch\n",
    "    def __getitem__(self, i):\n",
    "        startind = self.start_indices[i]\n",
    "        try:\n",
    "            endind = self.start_indices[i+1] #this is the first of the NEXT patient so do NOT INCLUDE!\n",
    "        except: #last patient\n",
    "            endind = len(self.all_labels)\n",
    "        \n",
    "        img_frames = self.all_frames[startind:endind] #feature vectors. img_frames should be size (numimgsinpatient, 2)\n",
    "        annot_ids = self.all_annot_ids[startind:endind] #should be all the same, annot_ids should be size (numimgsinpatient)\n",
    "        intannot_ids = []\n",
    "        \n",
    "        #create labels for images\n",
    "        labels = torch.LongTensor(endind-startind)\n",
    "        for l in range(0, endind-startind):\n",
    "            labels[l] = int(self.all_labels[startind+l]) #should be all the same, labels should be size (numimgsinpatient)\n",
    "            intannot_ids.append(int(annot_ids[l][:-1])) #make into integer\n",
    "        \n",
    "        inputs = torch.from_numpy(img_frames).float()\n",
    "        \n",
    "        intannot_ids = np.array(intannot_ids)\n",
    "        intannot_ids = torch.from_numpy(intannot_ids)\n",
    "        \n",
    "        framenums = self.all_frame_nums[startind:endind] #frame nums, should be in order\n",
    "\n",
    "        for i in range(len(framenums)):\n",
    "            framenums[i] = float(framenums[i])\n",
    "        framenums = np.array(framenums, dtype=np.float32)\n",
    "        framenums = torch.from_numpy(framenums).float()\n",
    "        \n",
    "        return {'input': inputs, 'label': labels, 'annot_id': intannot_ids, 'framenum': framenums}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0374258e-95d5-483a-ac97-3cd2e5c64fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVPHASE: 0 \n",
      "csv: backbone_embeddings/mobilenet_embeddings_ALL_IMAGES.csv\n",
      "opened csv for cnn features\n",
      "row: 0\n",
      "row: 500\n",
      "row: 1000\n",
      "row: 1500\n",
      "row: 2000\n",
      "row: 2500\n",
      "row: 3000\n",
      "row: 3500\n",
      "row: 4000\n",
      "row: 4500\n",
      "row: 5000\n",
      "row: 5500\n",
      "rowcount 5661\n",
      "length of probs, labels, ids 5661 5661 5661\n",
      "type of cur_all_pat_inds <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "\n",
      " should be sorted (framenums, patient id, label): (2.0, 5.0, 8.0, 11.0, 14.0, 17.0, 20.0, 23.0, 26.0, 29.0) ('100_', '100_', '100_', '100_', '100_', '100_', '100_', '100_', '100_', '100_') ('0', '0', '0', '0', '0', '0', '0', '0', '0', '0')\n",
      "\n",
      "\n",
      "LOADING train PHASE\n",
      "patient 100_ : CNN extracted # of frames = 13\n",
      "patient 101_ : CNN extracted # of frames = 20\n",
      "patient 102_ : CNN extracted # of frames = 29\n",
      "patient 103_ : CNN extracted # of frames = 22\n",
      "patient 104_ : CNN extracted # of frames = 33\n",
      "patient 105_ : CNN extracted # of frames = 14\n",
      "patient 106_ : CNN extracted # of frames = 20\n",
      "patient 108_ : CNN extracted # of frames = 40\n",
      "patient 109_ : CNN extracted # of frames = 40\n",
      "patient 10_ : CNN extracted # of frames = 45\n",
      "patient 110_ : CNN extracted # of frames = 15\n",
      "patient 111_ : CNN extracted # of frames = 24\n",
      "patient 112_ : CNN extracted # of frames = 18\n",
      "patient 114_ : CNN extracted # of frames = 79\n",
      "patient 116_ : CNN extracted # of frames = 46\n",
      "patient 117_ : CNN extracted # of frames = 34\n",
      "patient 118_ : CNN extracted # of frames = 11\n",
      "patient 11_ : CNN extracted # of frames = 54\n",
      "patient 120_ : CNN extracted # of frames = 12\n",
      "patient 121_ : CNN extracted # of frames = 13\n",
      "patient 122_ : CNN extracted # of frames = 29\n",
      "patient 123_ : CNN extracted # of frames = 34\n",
      "patient 124_ : CNN extracted # of frames = 12\n",
      "patient 125_ : CNN extracted # of frames = 40\n",
      "patient 126_ : CNN extracted # of frames = 11\n",
      "patient 127_ : CNN extracted # of frames = 28\n",
      "patient 128_ : CNN extracted # of frames = 56\n",
      "patient 129_ : CNN extracted # of frames = 41\n",
      "patient 12_ : CNN extracted # of frames = 25\n",
      "patient 130_ : CNN extracted # of frames = 25\n",
      "patient 132_ : CNN extracted # of frames = 41\n",
      "patient 133_ : CNN extracted # of frames = 36\n",
      "patient 134_ : CNN extracted # of frames = 55\n",
      "patient 136_ : CNN extracted # of frames = 55\n",
      "patient 137_ : CNN extracted # of frames = 33\n",
      "patient 138_ : CNN extracted # of frames = 36\n",
      "patient 139_ : CNN extracted # of frames = 22\n",
      "patient 140_ : CNN extracted # of frames = 38\n",
      "patient 141_ : CNN extracted # of frames = 25\n",
      "patient 142_ : CNN extracted # of frames = 3\n",
      "patient 143_ : CNN extracted # of frames = 51\n",
      "patient 144_ : CNN extracted # of frames = 12\n",
      "patient 145_ : CNN extracted # of frames = 44\n",
      "patient 146_ : CNN extracted # of frames = 36\n",
      "patient 147_ : CNN extracted # of frames = 8\n",
      "patient 148_ : CNN extracted # of frames = 147\n",
      "patient 149_ : CNN extracted # of frames = 18\n",
      "patient 14_ : CNN extracted # of frames = 17\n",
      "patient 150_ : CNN extracted # of frames = 37\n",
      "patient 151_ : CNN extracted # of frames = 34\n",
      "patient 152_ : CNN extracted # of frames = 10\n",
      "patient 153_ : CNN extracted # of frames = 23\n",
      "patient 154_ : CNN extracted # of frames = 25\n",
      "patient 155_ : CNN extracted # of frames = 33\n",
      "patient 157_ : CNN extracted # of frames = 76\n",
      "patient 159_ : CNN extracted # of frames = 7\n",
      "patient 15_ : CNN extracted # of frames = 42\n",
      "patient 160_ : CNN extracted # of frames = 49\n",
      "patient 161_ : CNN extracted # of frames = 4\n",
      "patient 162_ : CNN extracted # of frames = 18\n",
      "patient 163_ : CNN extracted # of frames = 21\n",
      "patient 164_ : CNN extracted # of frames = 29\n",
      "patient 165_ : CNN extracted # of frames = 35\n",
      "patient 166_ : CNN extracted # of frames = 12\n",
      "patient 167_ : CNN extracted # of frames = 11\n",
      "patient 169_ : CNN extracted # of frames = 23\n",
      "patient 16_ : CNN extracted # of frames = 38\n",
      "patient 170_ : CNN extracted # of frames = 7\n",
      "patient 171_ : CNN extracted # of frames = 24\n",
      "patient 172_ : CNN extracted # of frames = 34\n",
      "patient 173_ : CNN extracted # of frames = 8\n",
      "patient 174_ : CNN extracted # of frames = 15\n",
      "patient 175_ : CNN extracted # of frames = 25\n",
      "patient 176_ : CNN extracted # of frames = 42\n",
      "patient 177_ : CNN extracted # of frames = 29\n",
      "patient 178_ : CNN extracted # of frames = 10\n",
      "patient 179_ : CNN extracted # of frames = 23\n",
      "patient 17_ : CNN extracted # of frames = 15\n",
      "patient 180_ : CNN extracted # of frames = 50\n",
      "patient 181_ : CNN extracted # of frames = 37\n",
      "patient 182_ : CNN extracted # of frames = 16\n",
      "patient 183_ : CNN extracted # of frames = 71\n",
      "patient 184_ : CNN extracted # of frames = 97\n",
      "patient 185_ : CNN extracted # of frames = 28\n",
      "patient 186_ : CNN extracted # of frames = 43\n",
      "patient 188_ : CNN extracted # of frames = 30\n",
      "patient 189_ : CNN extracted # of frames = 20\n",
      "patient 18_ : CNN extracted # of frames = 19\n",
      "patient 190_ : CNN extracted # of frames = 50\n",
      "patient 191_ : CNN extracted # of frames = 10\n",
      "patient 192_ : CNN extracted # of frames = 37\n",
      "patient 193_ : CNN extracted # of frames = 21\n",
      "patient 194_ : CNN extracted # of frames = 29\n",
      "patient 195_ : CNN extracted # of frames = 28\n",
      "patient 196_ : CNN extracted # of frames = 27\n",
      "patient 197_ : CNN extracted # of frames = 29\n",
      "patient 198_ : CNN extracted # of frames = 51\n",
      "patient 199_ : CNN extracted # of frames = 37\n",
      "patient 1_ : CNN extracted # of frames = 13\n",
      "patient 200_ : CNN extracted # of frames = 20\n",
      "patient 201_ : CNN extracted # of frames = 10\n",
      "patient 202_ : CNN extracted # of frames = 18\n",
      "patient 203_ : CNN extracted # of frames = 12\n",
      "patient 204_ : CNN extracted # of frames = 14\n",
      "patient 206_ : CNN extracted # of frames = 41\n",
      "patient 207_ : CNN extracted # of frames = 10\n",
      "patient 208_ : CNN extracted # of frames = 20\n",
      "patient 209_ : CNN extracted # of frames = 14\n",
      "patient 20_ : CNN extracted # of frames = 17\n",
      "patient 210_ : CNN extracted # of frames = 60\n",
      "patient 211_ : CNN extracted # of frames = 23\n",
      "patient 212_ : CNN extracted # of frames = 26\n",
      "patient 213_ : CNN extracted # of frames = 50\n",
      "patient 214_ : CNN extracted # of frames = 36\n",
      "patient 21_ : CNN extracted # of frames = 27\n",
      "patient 22_ : CNN extracted # of frames = 55\n",
      "patient 23_ : CNN extracted # of frames = 12\n",
      "patient 24_ : CNN extracted # of frames = 58\n",
      "patient 25_ : CNN extracted # of frames = 26\n",
      "patient 27_ : CNN extracted # of frames = 9\n",
      "patient 28_ : CNN extracted # of frames = 83\n",
      "patient 29_ : CNN extracted # of frames = 43\n",
      "patient 2_ : CNN extracted # of frames = 39\n",
      "patient 30_ : CNN extracted # of frames = 61\n",
      "patient 31_ : CNN extracted # of frames = 22\n",
      "patient 33_ : CNN extracted # of frames = 12\n",
      "patient 34_ : CNN extracted # of frames = 29\n",
      "patient 35_ : CNN extracted # of frames = 28\n",
      "patient 36_ : CNN extracted # of frames = 15\n",
      "patient 37_ : CNN extracted # of frames = 57\n",
      "patient 39_ : CNN extracted # of frames = 20\n",
      "patient 3_ : CNN extracted # of frames = 59\n",
      "patient 40_ : CNN extracted # of frames = 22\n",
      "patient 41_ : CNN extracted # of frames = 19\n",
      "patient 42_ : CNN extracted # of frames = 29\n",
      "patient 43_ : CNN extracted # of frames = 30\n",
      "patient 45_ : CNN extracted # of frames = 34\n",
      "patient 46_ : CNN extracted # of frames = 26\n",
      "patient 48_ : CNN extracted # of frames = 23\n",
      "patient 49_ : CNN extracted # of frames = 23\n",
      "patient 4_ : CNN extracted # of frames = 41\n",
      "patient 50_ : CNN extracted # of frames = 36\n",
      "patient 51_ : CNN extracted # of frames = 26\n",
      "patient 53_ : CNN extracted # of frames = 15\n",
      "patient 55_ : CNN extracted # of frames = 26\n",
      "patient 56_ : CNN extracted # of frames = 23\n",
      "patient 57_ : CNN extracted # of frames = 38\n",
      "patient 58_ : CNN extracted # of frames = 35\n",
      "patient 5_ : CNN extracted # of frames = 15\n",
      "patient 60_ : CNN extracted # of frames = 51\n",
      "patient 61_ : CNN extracted # of frames = 8\n",
      "patient 62_ : CNN extracted # of frames = 13\n",
      "patient 63_ : CNN extracted # of frames = 49\n",
      "patient 64_ : CNN extracted # of frames = 14\n",
      "patient 65_ : CNN extracted # of frames = 29\n",
      "patient 66_ : CNN extracted # of frames = 29\n",
      "patient 67_ : CNN extracted # of frames = 18\n",
      "patient 68_ : CNN extracted # of frames = 42\n",
      "patient 69_ : CNN extracted # of frames = 26\n",
      "patient 6_ : CNN extracted # of frames = 31\n",
      "patient 70_ : CNN extracted # of frames = 80\n",
      "patient 71_ : CNN extracted # of frames = 44\n",
      "patient 72_ : CNN extracted # of frames = 49\n",
      "patient 73_ : CNN extracted # of frames = 14\n",
      "patient 74_ : CNN extracted # of frames = 13\n",
      "patient 75_ : CNN extracted # of frames = 29\n",
      "patient 76_ : CNN extracted # of frames = 8\n",
      "patient 78_ : CNN extracted # of frames = 27\n",
      "patient 79_ : CNN extracted # of frames = 17\n",
      "patient 7_ : CNN extracted # of frames = 19\n",
      "patient 80_ : CNN extracted # of frames = 6\n",
      "patient 81_ : CNN extracted # of frames = 26\n",
      "patient 82_ : CNN extracted # of frames = 15\n",
      "patient 83_ : CNN extracted # of frames = 50\n",
      "patient 84_ : CNN extracted # of frames = 24\n",
      "patient 85_ : CNN extracted # of frames = 42\n",
      "patient 86_ : CNN extracted # of frames = 39\n",
      "patient 87_ : CNN extracted # of frames = 45\n",
      "patient 88_ : CNN extracted # of frames = 24\n",
      "patient 89_ : CNN extracted # of frames = 32\n",
      "patient 8_ : CNN extracted # of frames = 17\n",
      "patient 90_ : CNN extracted # of frames = 44\n",
      "patient 91_ : CNN extracted # of frames = 6\n",
      "patient 92_ : CNN extracted # of frames = 19\n",
      "patient 93_ : CNN extracted # of frames = 8\n",
      "patient 94_ : CNN extracted # of frames = 10\n",
      "patient 95_ : CNN extracted # of frames = 21\n",
      "patient 96_ : CNN extracted # of frames = 10\n",
      "patient 97_ : CNN extracted # of frames = 14\n",
      "patient 98_ : CNN extracted # of frames = 27\n",
      "patient 99_ : CNN extracted # of frames = 16\n",
      "patient 9_ : CNN extracted # of frames = 7\n",
      "cur all probs shape (5661, 358)\n",
      "num patients: 192  total length: 5661\n",
      "opened csv to concatenate manual features\n",
      "row: 0 curind 1\n",
      "row: 5000 curind 2671\n",
      "rowcount 5661\n",
      "from concat features: pats 160_\n",
      "looping through all feature vectors, index 0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 100_ cnn framenum: 38.0 vs. 2.0 to 38.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 101_ cnn framenum: 59.0 vs. 2.0 to 59.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 102_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 103_ cnn framenum: 66.0 vs. 3.0 to 66.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 104_ cnn framenum: 99.0 vs. 3.0 to 99.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 105_ cnn framenum: 40.0 vs. 1.0 to 40.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 106_ cnn framenum: 60.0 vs. 3.0 to 60.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 108_ cnn framenum: 120.0 vs. 3.0 to 120.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 109_ cnn framenum: 119.0 vs. 2.0 to 119.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 10_ cnn framenum: 135.0 vs. 3.0 to 135.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 110_ cnn framenum: 44.0 vs. 2.0 to 44.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 111_ cnn framenum: 70.0 vs. 1.0 to 70.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 112_ cnn framenum: 52.0 vs. 1.0 to 52.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 114_ cnn framenum: 237.0 vs. 3.0 to 237.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 116_ cnn framenum: 137.0 vs. 2.0 to 137.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 117_ cnn framenum: 101.0 vs. 2.0 to 101.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 118_ cnn framenum: 32.0 vs. 2.0 to 32.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 11_ cnn framenum: 162.0 vs. 3.0 to 162.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 120_ cnn framenum: 34.0 vs. 1.0 to 34.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 121_ cnn framenum: 39.0 vs. 3.0 to 39.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 122_ cnn framenum: 85.0 vs. 1.0 to 85.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 123_ cnn framenum: 101.0 vs. 2.0 to 101.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 124_ cnn framenum: 34.0 vs. 1.0 to 34.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 125_ cnn framenum: 118.0 vs. 1.0 to 118.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 126_ cnn framenum: 31.0 vs. 1.0 to 31.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 127_ cnn framenum: 83.0 vs. 2.0 to 83.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 128_ cnn framenum: 168.0 vs. 3.0 to 168.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 129_ cnn framenum: 121.0 vs. 1.0 to 121.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 12_ cnn framenum: 75.0 vs. 3.0 to 75.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 130_ cnn framenum: 73.0 vs. 1.0 to 73.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 132_ cnn framenum: 123.0 vs. 3.0 to 123.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 133_ cnn framenum: 106.0 vs. 1.0 to 106.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "looping through all feature vectors, index 1000\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 134_ cnn framenum: 165.0 vs. 3.0 to 165.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 136_ cnn framenum: 164.0 vs. 2.0 to 164.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 137_ cnn framenum: 99.0 vs. 3.0 to 99.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 138_ cnn framenum: 107.0 vs. 2.0 to 107.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 139_ cnn framenum: 66.0 vs. 3.0 to 66.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 140_ cnn framenum: 121.0 vs. 1.0 to 121.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 141_ cnn framenum: 73.0 vs. 1.0 to 73.0\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 142_ cnn framenum: 8.0 vs. 2.0 to 8.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 143_ cnn framenum: 153.0 vs. 3.0 to 153.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 144_ cnn framenum: 34.0 vs. 1.0 to 34.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 145_ cnn framenum: 131.0 vs. 2.0 to 131.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 146_ cnn framenum: 107.0 vs. 2.0 to 107.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 147_ cnn framenum: 23.0 vs. 2.0 to 23.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 148_ cnn framenum: 440.0 vs. 2.0 to 440.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 149_ cnn framenum: 54.0 vs. 3.0 to 54.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 14_ cnn framenum: 50.0 vs. 2.0 to 50.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 150_ cnn framenum: 111.0 vs. 3.0 to 111.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 151_ cnn framenum: 101.0 vs. 2.0 to 101.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 152_ cnn framenum: 30.0 vs. 3.0 to 30.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 153_ cnn framenum: 69.0 vs. 3.0 to 69.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 154_ cnn framenum: 73.0 vs. 1.0 to 73.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 155_ cnn framenum: 99.0 vs. 3.0 to 99.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 157_ cnn framenum: 226.0 vs. 1.0 to 226.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 159_ cnn framenum: 20.0 vs. 2.0 to 20.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 15_ cnn framenum: 125.0 vs. 2.0 to 125.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 160_ cnn framenum: 145.0 vs. 1.0 to 145.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 161_ cnn framenum: 10.0 vs. 1.0 to 10.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 162_ cnn framenum: 53.0 vs. 2.0 to 53.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 163_ cnn framenum: 63.0 vs. 3.0 to 63.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 164_ cnn framenum: 86.0 vs. 2.0 to 86.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "looping through all feature vectors, index 2000\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 165_ cnn framenum: 104.0 vs. 2.0 to 104.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 166_ cnn framenum: 35.0 vs. 2.0 to 35.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 167_ cnn framenum: 31.0 vs. 1.0 to 31.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 169_ cnn framenum: 69.0 vs. 3.0 to 69.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 16_ cnn framenum: 114.0 vs. 3.0 to 114.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 170_ cnn framenum: 21.0 vs. 3.0 to 21.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 171_ cnn framenum: 72.0 vs. 3.0 to 72.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 172_ cnn framenum: 114.0 vs. 3.0 to 114.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 173_ cnn framenum: 23.0 vs. 2.0 to 23.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 174_ cnn framenum: 45.0 vs. 3.0 to 45.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 175_ cnn framenum: 74.0 vs. 2.0 to 74.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 176_ cnn framenum: 126.0 vs. 3.0 to 126.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 177_ cnn framenum: 85.0 vs. 1.0 to 85.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 178_ cnn framenum: 30.0 vs. 3.0 to 30.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 179_ cnn framenum: 69.0 vs. 3.0 to 69.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 17_ cnn framenum: 43.0 vs. 1.0 to 43.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 180_ cnn framenum: 149.0 vs. 2.0 to 149.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 181_ cnn framenum: 111.0 vs. 3.0 to 111.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 182_ cnn framenum: 48.0 vs. 3.0 to 48.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 183_ cnn framenum: 213.0 vs. 3.0 to 213.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 184_ cnn framenum: 290.0 vs. 2.0 to 290.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 185_ cnn framenum: 83.0 vs. 2.0 to 83.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 186_ cnn framenum: 128.0 vs. 2.0 to 128.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 188_ cnn framenum: 90.0 vs. 3.0 to 90.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 189_ cnn framenum: 59.0 vs. 2.0 to 59.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 18_ cnn framenum: 57.0 vs. 3.0 to 57.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 190_ cnn framenum: 149.0 vs. 2.0 to 149.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 191_ cnn framenum: 28.0 vs. 1.0 to 28.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 192_ cnn framenum: 111.0 vs. 3.0 to 111.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 193_ cnn framenum: 61.0 vs. 1.0 to 61.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 194_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 195_ cnn framenum: 83.0 vs. 2.0 to 83.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 196_ cnn framenum: 81.0 vs. 3.0 to 81.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 197_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "looping through all feature vectors, index 3000\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 198_ cnn framenum: 152.0 vs. 2.0 to 152.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 199_ cnn framenum: 111.0 vs. 3.0 to 111.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 1_ cnn framenum: 38.0 vs. 2.0 to 38.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 200_ cnn framenum: 59.0 vs. 2.0 to 59.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 201_ cnn framenum: 28.0 vs. 1.0 to 28.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 202_ cnn framenum: 54.0 vs. 3.0 to 54.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 203_ cnn framenum: 36.0 vs. 3.0 to 36.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 204_ cnn framenum: 42.0 vs. 3.0 to 42.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 206_ cnn framenum: 121.0 vs. 1.0 to 121.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 207_ cnn framenum: 28.0 vs. 1.0 to 28.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 208_ cnn framenum: 60.0 vs. 3.0 to 60.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 209_ cnn framenum: 40.0 vs. 1.0 to 40.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 20_ cnn framenum: 51.0 vs. 3.0 to 51.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 210_ cnn framenum: 180.0 vs. 3.0 to 180.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 211_ cnn framenum: 68.0 vs. 2.0 to 68.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 212_ cnn framenum: 77.0 vs. 2.0 to 77.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 213_ cnn framenum: 148.0 vs. 1.0 to 148.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 214_ cnn framenum: 107.0 vs. 2.0 to 107.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 21_ cnn framenum: 79.0 vs. 1.0 to 79.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 22_ cnn framenum: 163.0 vs. 1.0 to 163.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 23_ cnn framenum: 34.0 vs. 1.0 to 34.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 24_ cnn framenum: 173.0 vs. 2.0 to 173.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 25_ cnn framenum: 77.0 vs. 2.0 to 77.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 27_ cnn framenum: 26.0 vs. 2.0 to 26.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 28_ cnn framenum: 249.0 vs. 3.0 to 249.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 29_ cnn framenum: 129.0 vs. 3.0 to 129.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 2_ cnn framenum: 117.0 vs. 3.0 to 117.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 30_ cnn framenum: 183.0 vs. 3.0 to 183.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 31_ cnn framenum: 66.0 vs. 3.0 to 66.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 33_ cnn framenum: 36.0 vs. 3.0 to 36.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 34_ cnn framenum: 85.0 vs. 1.0 to 85.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 35_ cnn framenum: 82.0 vs. 1.0 to 82.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 36_ cnn framenum: 43.0 vs. 1.0 to 43.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "looping through all feature vectors, index 4000\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 37_ cnn framenum: 171.0 vs. 3.0 to 171.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 39_ cnn framenum: 58.0 vs. 1.0 to 58.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 3_ cnn framenum: 177.0 vs. 3.0 to 177.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 40_ cnn framenum: 64.0 vs. 1.0 to 64.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 41_ cnn framenum: 55.0 vs. 1.0 to 55.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 42_ cnn framenum: 86.0 vs. 2.0 to 86.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 43_ cnn framenum: 90.0 vs. 3.0 to 90.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 45_ cnn framenum: 100.0 vs. 1.0 to 100.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 46_ cnn framenum: 78.0 vs. 3.0 to 78.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 48_ cnn framenum: 67.0 vs. 1.0 to 67.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 49_ cnn framenum: 67.0 vs. 1.0 to 67.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 4_ cnn framenum: 121.0 vs. 1.0 to 121.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 50_ cnn framenum: 107.0 vs. 2.0 to 107.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 51_ cnn framenum: 77.0 vs. 2.0 to 77.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 53_ cnn framenum: 45.0 vs. 3.0 to 45.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 55_ cnn framenum: 78.0 vs. 3.0 to 78.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 56_ cnn framenum: 67.0 vs. 1.0 to 67.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 57_ cnn framenum: 112.0 vs. 1.0 to 112.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 58_ cnn framenum: 104.0 vs. 2.0 to 104.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 5_ cnn framenum: 43.0 vs. 1.0 to 43.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 60_ cnn framenum: 153.0 vs. 3.0 to 153.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 61_ cnn framenum: 22.0 vs. 1.0 to 22.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 62_ cnn framenum: 38.0 vs. 2.0 to 38.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 63_ cnn framenum: 145.0 vs. 1.0 to 145.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 64_ cnn framenum: 42.0 vs. 3.0 to 42.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 65_ cnn framenum: 85.0 vs. 1.0 to 85.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 66_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 67_ cnn framenum: 54.0 vs. 3.0 to 54.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 68_ cnn framenum: 126.0 vs. 3.0 to 126.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 69_ cnn framenum: 77.0 vs. 2.0 to 77.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 6_ cnn framenum: 93.0 vs. 3.0 to 93.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 70_ cnn framenum: 240.0 vs. 3.0 to 240.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 71_ cnn framenum: 130.0 vs. 1.0 to 130.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "looping through all feature vectors, index 5000\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 72_ cnn framenum: 145.0 vs. 1.0 to 145.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 73_ cnn framenum: 40.0 vs. 1.0 to 40.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 74_ cnn framenum: 38.0 vs. 2.0 to 38.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 75_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 76_ cnn framenum: 23.0 vs. 2.0 to 23.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 78_ cnn framenum: 79.0 vs. 1.0 to 79.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 79_ cnn framenum: 49.0 vs. 1.0 to 49.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 7_ cnn framenum: 57.0 vs. 3.0 to 57.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 80_ cnn framenum: 18.0 vs. 3.0 to 18.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 81_ cnn framenum: 77.0 vs. 2.0 to 77.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 82_ cnn framenum: 44.0 vs. 2.0 to 44.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 83_ cnn framenum: 150.0 vs. 3.0 to 150.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 84_ cnn framenum: 71.0 vs. 2.0 to 71.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 85_ cnn framenum: 125.0 vs. 2.0 to 125.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 86_ cnn framenum: 116.0 vs. 2.0 to 116.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 87_ cnn framenum: 135.0 vs. 3.0 to 135.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 88_ cnn framenum: 71.0 vs. 2.0 to 71.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 89_ cnn framenum: 95.0 vs. 2.0 to 95.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 8_ cnn framenum: 49.0 vs. 1.0 to 49.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 90_ cnn framenum: 131.0 vs. 2.0 to 131.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 91_ cnn framenum: 17.0 vs. 2.0 to 17.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 92_ cnn framenum: 56.0 vs. 2.0 to 56.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 93_ cnn framenum: 24.0 vs. 3.0 to 24.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 94_ cnn framenum: 30.0 vs. 3.0 to 30.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 95_ cnn framenum: 61.0 vs. 1.0 to 61.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 96_ cnn framenum: 30.0 vs. 3.0 to 30.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 97_ cnn framenum: 41.0 vs. 2.0 to 41.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 98_ cnn framenum: 79.0 vs. 1.0 to 79.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 99_ cnn framenum: 46.0 vs. 1.0 to 46.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "over limit; gg, features 5659 len avg features and concats 3 256\n",
      "(256,)\n",
      "framenum notmatching 9_ cnn framenum: 20.0 vs. 2.0 to 20.0\n",
      "\n",
      "\n",
      "FOUND total of 5469 corresponding 2d features vs. total of 5661 frames\n",
      "train PATIENTS: ('142_', '161_', '80_', '91_', '159_', '170_', '9_', '147_', '173_', '61_', '76_', '93_', '27_', '152_', '178_', '191_', '201_', '207_', '94_', '96_', '118_', '126_', '167_', '120_', '124_', '144_', '166_', '203_', '23_', '33_', '100_', '121_', '1_', '62_', '74_', '105_', '204_', '209_', '64_', '73_', '97_', '110_', '174_', '17_', '36_', '53_', '5_', '82_', '182_', '99_', '14_', '20_', '79_', '8_', '112_', '149_', '162_', '202_', '67_', '18_', '41_', '7_', '92_', '101_', '106_', '189_', '200_', '208_', '39_', '163_', '193_', '95_', '103_', '139_', '31_', '40_', '153_', '169_', '179_', '211_', '48_', '49_', '56_', '111_', '171_', '84_', '88_', '12_', '130_', '141_', '154_', '175_', '212_', '25_', '46_', '51_', '55_', '69_', '81_', '196_', '21_', '78_', '98_', '127_', '185_', '195_', '35_', '102_', '122_', '164_', '177_', '194_', '197_', '34_', '42_', '65_', '66_', '75_', '188_', '43_', '6_', '89_', '104_', '137_', '155_', '117_', '123_', '151_', '172_', '45_', '165_', '58_', '133_', '138_', '146_', '214_', '50_', '150_', '181_', '192_', '199_', '140_', '16_', '57_', '2_', '86_', '108_', '109_', '125_', '129_', '132_', '206_', '4_', '15_', '176_', '68_', '85_', '186_', '29_', '145_', '71_', '90_', '10_', '87_', '116_', '160_', '63_', '72_', '180_', '190_', '213_', '83_', '143_', '198_', '60_', '11_', '134_', '136_', '22_', '128_', '37_', '24_', '3_', '210_', '30_', '183_', '157_', '114_', '70_', '28_', '184_', '148_')\n",
      "cvphase 0 numpatients input: 192\n",
      "example features:\n",
      " 1.2005491256713867 0.5593774766621006 0.4369095125639726\n",
      "\n",
      "FINAL features, labels, ids shapes (9180, 358) (9180,) (9180,) (9180,)\n",
      "numiters 255.0\n",
      "done reading in images and labels for train !!!\n",
      "\n",
      "\n",
      "start indices (should be multiples of sequence length only): [0, 36, 72, 108, 144, 180, 216, 252, 288, 324, 360, 396, 432, 468, 504, 540, 576, 612, 648, 684, 720, 756, 792, 828, 864, 900, 936, 972, 1008, 1044, 1080, 1116, 1152, 1188, 1224, 1260, 1296, 1332, 1368, 1404, 1440, 1476, 1512, 1548, 1584, 1620, 1656, 1692, 1728, 1764, 1800, 1836, 1872, 1908, 1944, 1980, 2016, 2052, 2088, 2124, 2160, 2196, 2232, 2268, 2304, 2340, 2376, 2412, 2448, 2484, 2520, 2556, 2592, 2628, 2664, 2700, 2736, 2772, 2808, 2844, 2880, 2916, 2952, 2988, 3024, 3060, 3096, 3132, 3168, 3204, 3240, 3276, 3312, 3348, 3384, 3420, 3456, 3492, 3528, 3564, 3600, 3636, 3672, 3708, 3744, 3780, 3816, 3852, 3888, 3924, 3960, 3996, 4032, 4068, 4104, 4140, 4176, 4212, 4248, 4284, 4320, 4356, 4392, 4428, 4464, 4500, 4536, 4572, 4608, 4644, 4680, 4716, 4752, 4788, 4824, 4860, 4896, 4932, 4968, 5004, 5040, 5076, 5112, 5148, 5184, 5220, 5256, 5292, 5328, 5364, 5400, 5436, 5472, 5508, 5544, 5580, 5616, 5652, 5688, 5724, 5760, 5796, 5832, 5868, 5904, 5940, 5976, 6012, 6048, 6084, 6120, 6156, 6192, 6228, 6264, 6300, 6336, 6372, 6408, 6444, 6480, 6516, 6552, 6588, 6624, 6660, 6696, 6732, 6768, 6804, 6840, 6876, 6912, 6948, 6984, 7020, 7056, 7092, 7128, 7164, 7200, 7236, 7272, 7308, 7344, 7380, 7416, 7452, 7488, 7524, 7560, 7596, 7632, 7668, 7704, 7740, 7776, 7812, 7848, 7884, 7920, 7956, 7992, 8028, 8064, 8100, 8136, 8172, 8208, 8244, 8280, 8316, 8352, 8388, 8424, 8460, 8496, 8532, 8568, 8604, 8640, 8676, 8712, 8748, 8784, 8820, 8856, 8892, 8928, 8964, 9000, 9036, 9072, 9108, 9144]\n",
      "all frames: 9180 (9180, 358)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = DatasetPaddedTransformer(\"train\", 0, True, False, \"adjacent\", \".\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5c693-f618-4211-a13a-a8eb3099b205",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a66631d9-8112-4349-b287-8532a56aa4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    " patientwise_auroc = 0\n",
    "#learning rate\n",
    "lrs = []\n",
    "\n",
    "seed_value = 1\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "losses = []\n",
    "#f_losses = []\n",
    "losses_val = []\n",
    "#f_losses_val = []\n",
    "\n",
    "running_loss = 0.0\n",
    "running_loss_val = 0.0\n",
    "\n",
    "total_all = 0\n",
    "correct_all = 0\n",
    "\n",
    "transall_labels = []\n",
    "all_probs_ones = []\n",
    "transall_patients = [] #val\n",
    "train_transall_patients = [] #train\n",
    "\n",
    "tlabelsnp = np.zeros(16)\n",
    "\n",
    "epoch_aurocs = []\n",
    "\n",
    "#default for early stopping\n",
    "min_val_loss = 10\n",
    "prev_val_loss = 10\n",
    "epochs_no_improve = 0\n",
    "n_epochs_stop = 5\n",
    "early_stop = False\n",
    "min_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15bf36a-f2f5-472f-a448-f6184b4eb4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 13 04:07:08 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080        Off | 00000000:08:00.0  On |                  N/A |\n",
      "|  0%   40C    P8              46W / 370W |    339MiB / 10240MiB |     22%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1401      G   /usr/lib/xorg/Xorg                          167MiB |\n",
      "|    0   N/A  N/A      1682      G   /usr/bin/gnome-shell                         30MiB |\n",
      "|    0   N/A  N/A      2415      G   ...ures=SpareRendererForSitePerProcess       15MiB |\n",
      "|    0   N/A  N/A      2710      G   ...0279101,18231513973801386308,262144      104MiB |\n",
      "|    0   N/A  N/A      2945      G   /home/iadam/.local/kitty.app/bin/kitty        6MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a6c5512-2d13-4080-8ca3-8ef7bae844d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "018822d3-f761-400c-9c3e-5fb6869b5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer in size 358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iadam/miniconda3/envs/replicate_thyroid2/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel(256+102, use_position_enc= False)#number of features in each.\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14eabd29-36ca-4c93-9968-975ac76fc351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding weights to loss function because of imbalance in dataset\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), 0.001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, 0.001, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fd2d76-79ad-4f22-9a4d-42f455338363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVPHASE: 1 \n",
      "csv: backbone_embeddings/mobilenet_embeddings_FOLD1.csv\n",
      "opened csv for cnn features\n",
      "row: 0\n",
      "row: 500\n",
      "row: 1000\n",
      "rowcount 1136\n",
      "length of probs, labels, ids 1136 1136 1136\n",
      "type of cur_all_pat_inds <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "\n",
      " should be sorted (framenums, patient id, label): (3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0, 27.0, 30.0) ('102_', '102_', '102_', '102_', '102_', '102_', '102_', '102_', '102_', '102_') ('0', '0', '0', '0', '0', '0', '0', '0', '0', '0')\n",
      "\n",
      "\n",
      "LOADING train PHASE\n",
      "patient 102_ : CNN extracted # of frames = 29\n",
      "patient 105_ : CNN extracted # of frames = 14\n",
      "patient 109_ : CNN extracted # of frames = 40\n",
      "patient 110_ : CNN extracted # of frames = 15\n",
      "patient 116_ : CNN extracted # of frames = 46\n",
      "patient 11_ : CNN extracted # of frames = 55\n",
      "patient 125_ : CNN extracted # of frames = 39\n",
      "patient 126_ : CNN extracted # of frames = 11\n",
      "patient 138_ : CNN extracted # of frames = 36\n",
      "patient 143_ : CNN extracted # of frames = 51\n",
      "patient 160_ : CNN extracted # of frames = 49\n",
      "patient 161_ : CNN extracted # of frames = 4\n",
      "patient 173_ : CNN extracted # of frames = 8\n",
      "patient 174_ : CNN extracted # of frames = 15\n",
      "patient 175_ : CNN extracted # of frames = 25\n",
      "patient 176_ : CNN extracted # of frames = 42\n",
      "patient 178_ : CNN extracted # of frames = 10\n",
      "patient 183_ : CNN extracted # of frames = 71\n",
      "patient 184_ : CNN extracted # of frames = 97\n",
      "patient 213_ : CNN extracted # of frames = 50\n",
      "patient 214_ : CNN extracted # of frames = 36\n",
      "patient 22_ : CNN extracted # of frames = 5\n",
      "patient 31_ : CNN extracted # of frames = 22\n",
      "patient 34_ : CNN extracted # of frames = 29\n",
      "patient 35_ : CNN extracted # of frames = 28\n",
      "patient 43_ : CNN extracted # of frames = 12\n",
      "patient 46_ : CNN extracted # of frames = 27\n",
      "patient 57_ : CNN extracted # of frames = 38\n",
      "patient 63_ : CNN extracted # of frames = 49\n",
      "patient 70_ : CNN extracted # of frames = 53\n",
      "patient 71_ : CNN extracted # of frames = 44\n",
      "patient 73_ : CNN extracted # of frames = 14\n",
      "patient 75_ : CNN extracted # of frames = 29\n",
      "patient 76_ : CNN extracted # of frames = 7\n",
      "patient 88_ : CNN extracted # of frames = 15\n",
      "patient 91_ : CNN extracted # of frames = 6\n",
      "patient 93_ : CNN extracted # of frames = 8\n",
      "patient 9_ : CNN extracted # of frames = 7\n",
      "cur all probs shape (1136, 358)\n",
      "num patients: 38  total length: 1136\n",
      "opened csv to concatenate manual features\n",
      "row: 0 curind 1\n",
      "rowcount 1136\n",
      "from concat features: pats 160_\n",
      "looping through all feature vectors, index 0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 102_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 105_ cnn framenum: 40.0 vs. 1.0 to 40.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 109_ cnn framenum: 119.0 vs. 2.0 to 119.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 110_ cnn framenum: 45.0 vs. 3.0 to 45.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 116_ cnn framenum: 138.0 vs. 3.0 to 138.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 11_ cnn framenum: 163.0 vs. 1.0 to 163.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 125_ cnn framenum: 116.0 vs. 2.0 to 116.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 126_ cnn framenum: 32.0 vs. 2.0 to 32.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 138_ cnn framenum: 107.0 vs. 2.0 to 107.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 143_ cnn framenum: 153.0 vs. 3.0 to 153.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 160_ cnn framenum: 145.0 vs. 1.0 to 145.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 161_ cnn framenum: 10.0 vs. 1.0 to 10.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 173_ cnn framenum: 24.0 vs. 3.0 to 24.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 174_ cnn framenum: 45.0 vs. 3.0 to 45.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 175_ cnn framenum: 74.0 vs. 2.0 to 74.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 176_ cnn framenum: 126.0 vs. 3.0 to 126.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 178_ cnn framenum: 30.0 vs. 3.0 to 30.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 183_ cnn framenum: 213.0 vs. 3.0 to 213.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 184_ cnn framenum: 290.0 vs. 2.0 to 290.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 213_ cnn framenum: 148.0 vs. 1.0 to 148.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 214_ cnn framenum: 107.0 vs. 2.0 to 107.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 22_ cnn framenum: 13.0 vs. 1.0 to 13.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 31_ cnn framenum: 64.0 vs. 1.0 to 64.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 34_ cnn framenum: 85.0 vs. 1.0 to 85.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 35_ cnn framenum: 83.0 vs. 2.0 to 83.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 43_ cnn framenum: 36.0 vs. 3.0 to 36.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 46_ cnn framenum: 79.0 vs. 1.0 to 79.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 57_ cnn framenum: 112.0 vs. 1.0 to 112.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 63_ cnn framenum: 145.0 vs. 1.0 to 145.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "looping through all feature vectors, index 1000\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 70_ cnn framenum: 159.0 vs. 3.0 to 159.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 71_ cnn framenum: 130.0 vs. 1.0 to 130.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 73_ cnn framenum: 40.0 vs. 1.0 to 40.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 75_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 76_ cnn framenum: 21.0 vs. 3.0 to 21.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 88_ cnn framenum: 45.0 vs. 3.0 to 45.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 91_ cnn framenum: 17.0 vs. 2.0 to 17.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 93_ cnn framenum: 24.0 vs. 3.0 to 24.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "over limit; gg, features 1134 len avg features and concats 3 256\n",
      "(256,)\n",
      "framenum notmatching 9_ cnn framenum: 21.0 vs. 3.0 to 21.0\n",
      "\n",
      "\n",
      "FOUND total of 1098 corresponding 2d features vs. total of 1136 frames\n",
      "train PATIENTS: ('161_', '22_', '91_', '76_', '9_', '173_', '93_', '178_', '126_', '43_', '105_', '73_', '110_', '174_', '88_', '31_', '175_', '46_', '35_', '102_', '34_', '75_', '138_', '214_', '57_', '125_', '109_', '176_', '71_', '116_', '160_', '63_', '213_', '143_', '70_', '11_', '183_', '184_')\n",
      "cvphase 1 numpatients input: 38\n",
      "example features:\n",
      " 0.4519985318183899 0.3825716513620314 0.2994614073305368\n",
      "\n",
      "FINAL features, labels, ids shapes (1908, 358) (1908,) (1908,) (1908,)\n",
      "numiters 53.0\n",
      "done reading in images and labels for train !!!\n",
      "\n",
      "\n",
      "start indices (should be multiples of sequence length only): [0, 36, 72, 108, 144, 180, 216, 252, 288, 324, 360, 396, 432, 468, 504, 540, 576, 612, 648, 684, 720, 756, 792, 828, 864, 900, 936, 972, 1008, 1044, 1080, 1116, 1152, 1188, 1224, 1260, 1296, 1332, 1368, 1404, 1440, 1476, 1512, 1548, 1584, 1620, 1656, 1692, 1728, 1764, 1800, 1836, 1872]\n",
      "all frames: 1908 (1908, 358)\n",
      "CVPHASE: 2 \n",
      "csv: backbone_embeddings/mobilenet_embeddings_FOLD2.csv\n",
      "opened csv for cnn features\n",
      "row: 0\n",
      "row: 500\n",
      "row: 1000\n",
      "rowcount 1122\n",
      "length of probs, labels, ids 1122 1122 1122\n",
      "type of cur_all_pat_inds <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "\n",
      " should be sorted (framenums, patient id, label): (2.0, 5.0, 8.0, 11.0, 14.0, 17.0, 20.0, 23.0, 26.0, 29.0) ('100_', '100_', '100_', '100_', '100_', '100_', '100_', '100_', '100_', '100_') ('0', '0', '0', '0', '0', '0', '0', '0', '0', '0')\n",
      "\n",
      "\n",
      "LOADING train PHASE\n",
      "patient 100_ : CNN extracted # of frames = 13\n",
      "patient 104_ : CNN extracted # of frames = 33\n",
      "patient 106_ : CNN extracted # of frames = 20\n",
      "patient 111_ : CNN extracted # of frames = 24\n",
      "patient 112_ : CNN extracted # of frames = 18\n",
      "patient 114_ : CNN extracted # of frames = 79\n",
      "patient 128_ : CNN extracted # of frames = 56\n",
      "patient 132_ : CNN extracted # of frames = 1\n",
      "patient 134_ : CNN extracted # of frames = 55\n",
      "patient 140_ : CNN extracted # of frames = 38\n",
      "patient 144_ : CNN extracted # of frames = 12\n",
      "patient 149_ : CNN extracted # of frames = 18\n",
      "patient 150_ : CNN extracted # of frames = 37\n",
      "patient 151_ : CNN extracted # of frames = 34\n",
      "patient 152_ : CNN extracted # of frames = 10\n",
      "patient 153_ : CNN extracted # of frames = 23\n",
      "patient 154_ : CNN extracted # of frames = 25\n",
      "patient 163_ : CNN extracted # of frames = 22\n",
      "patient 170_ : CNN extracted # of frames = 7\n",
      "patient 172_ : CNN extracted # of frames = 34\n",
      "patient 181_ : CNN extracted # of frames = 37\n",
      "patient 185_ : CNN extracted # of frames = 28\n",
      "patient 186_ : CNN extracted # of frames = 43\n",
      "patient 194_ : CNN extracted # of frames = 29\n",
      "patient 198_ : CNN extracted # of frames = 51\n",
      "patient 199_ : CNN extracted # of frames = 38\n",
      "patient 1_ : CNN extracted # of frames = 13\n",
      "patient 201_ : CNN extracted # of frames = 10\n",
      "patient 25_ : CNN extracted # of frames = 26\n",
      "patient 27_ : CNN extracted # of frames = 9\n",
      "patient 28_ : CNN extracted # of frames = 83\n",
      "patient 33_ : CNN extracted # of frames = 12\n",
      "patient 55_ : CNN extracted # of frames = 26\n",
      "patient 58_ : CNN extracted # of frames = 35\n",
      "patient 64_ : CNN extracted # of frames = 14\n",
      "patient 65_ : CNN extracted # of frames = 29\n",
      "patient 70_ : CNN extracted # of frames = 27\n",
      "patient 80_ : CNN extracted # of frames = 6\n",
      "patient 83_ : CNN extracted # of frames = 7\n",
      "patient 88_ : CNN extracted # of frames = 8\n",
      "patient 89_ : CNN extracted # of frames = 32\n",
      "cur all probs shape (1122, 358)\n",
      "num patients: 41  total length: 1122\n",
      "opened csv to concatenate manual features\n",
      "row: 0 curind 1\n",
      "rowcount 1122\n",
      "from concat features: pats 150_\n",
      "looping through all feature vectors, index 0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 100_ cnn framenum: 38.0 vs. 2.0 to 38.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 104_ cnn framenum: 99.0 vs. 3.0 to 99.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 106_ cnn framenum: 60.0 vs. 3.0 to 60.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 111_ cnn framenum: 70.0 vs. 1.0 to 70.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 112_ cnn framenum: 52.0 vs. 1.0 to 52.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 114_ cnn framenum: 237.0 vs. 3.0 to 237.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 128_ cnn framenum: 168.0 vs. 3.0 to 168.0\n",
      "framenum notmatching 132_ cnn framenum: 3.0 vs. 3.0 to 3.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 134_ cnn framenum: 165.0 vs. 3.0 to 165.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 140_ cnn framenum: 102.0 vs. 1.0 to 102.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 144_ cnn framenum: 34.0 vs. 1.0 to 34.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 149_ cnn framenum: 54.0 vs. 3.0 to 54.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 150_ cnn framenum: 111.0 vs. 3.0 to 111.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 151_ cnn framenum: 101.0 vs. 2.0 to 101.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 152_ cnn framenum: 30.0 vs. 3.0 to 30.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 153_ cnn framenum: 69.0 vs. 3.0 to 69.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 154_ cnn framenum: 73.0 vs. 1.0 to 73.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 163_ cnn framenum: 64.0 vs. 1.0 to 64.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 170_ cnn framenum: 21.0 vs. 3.0 to 21.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 172_ cnn framenum: 114.0 vs. 3.0 to 114.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 181_ cnn framenum: 111.0 vs. 3.0 to 111.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 185_ cnn framenum: 83.0 vs. 2.0 to 83.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 186_ cnn framenum: 128.0 vs. 2.0 to 128.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 194_ cnn framenum: 87.0 vs. 3.0 to 87.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 198_ cnn framenum: 152.0 vs. 2.0 to 152.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 199_ cnn framenum: 112.0 vs. 1.0 to 112.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 1_ cnn framenum: 38.0 vs. 2.0 to 38.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 201_ cnn framenum: 28.0 vs. 1.0 to 28.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 25_ cnn framenum: 77.0 vs. 2.0 to 77.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 27_ cnn framenum: 26.0 vs. 2.0 to 26.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 28_ cnn framenum: 249.0 vs. 3.0 to 249.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 33_ cnn framenum: 36.0 vs. 3.0 to 36.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 55_ cnn framenum: 78.0 vs. 3.0 to 78.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 58_ cnn framenum: 104.0 vs. 2.0 to 104.0\n",
      "(256,)\n",
      "looping through all feature vectors, index 1000\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 64_ cnn framenum: 42.0 vs. 3.0 to 42.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 65_ cnn framenum: 85.0 vs. 1.0 to 85.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 70_ cnn framenum: 79.0 vs. 1.0 to 79.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 80_ cnn framenum: 18.0 vs. 3.0 to 18.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 83_ cnn framenum: 21.0 vs. 3.0 to 21.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "framenum notmatching 88_ cnn framenum: 24.0 vs. 3.0 to 24.0\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "over limit; gg, features 1120 len avg features and concats 3 256\n",
      "(256,)\n",
      "framenum notmatching 89_ cnn framenum: 95.0 vs. 2.0 to 95.0\n",
      "\n",
      "\n",
      "FOUND total of 1081 corresponding 2d features vs. total of 1122 frames\n",
      "train PATIENTS: ('132_', '80_', '170_', '83_', '88_', '27_', '152_', '201_', '144_', '33_', '100_', '1_', '64_', '112_', '149_', '106_', '163_', '153_', '111_', '154_', '25_', '55_', '70_', '185_', '194_', '65_', '89_', '104_', '151_', '172_', '58_', '150_', '181_', '140_', '199_', '186_', '198_', '134_', '128_', '114_', '28_')\n",
      "cvphase 2 numpatients input: 41\n",
      "example features:\n",
      " 0.5549008846282959 0.0 0.0\n",
      "\n",
      "FINAL features, labels, ids shapes (1908, 358) (1908,) (1908,) (1908,)\n",
      "numiters 53.0\n",
      "done reading in images and labels for train !!!\n",
      "\n",
      "\n",
      "start indices (should be multiples of sequence length only): [0, 36, 72, 108, 144, 180, 216, 252, 288, 324, 360, 396, 432, 468, 504, 540, 576, 612, 648, 684, 720, 756, 792, 828, 864, 900, 936, 972, 1008, 1044, 1080, 1116, 1152, 1188, 1224, 1260, 1296, 1332, 1368, 1404, 1440, 1476, 1512, 1548, 1584, 1620, 1656, 1692, 1728, 1764, 1800, 1836, 1872]\n",
      "all frames: 1908 (1908, 358)\n"
     ]
    }
   ],
   "source": [
    "transformer_train_set = DatasetPaddedTransformer(\"train\", 1, True, False, \"adjacent\", \".\", False)\n",
    "transformer_test_set = DatasetPaddedTransformer(\"train\", 2, True, False, \"adjacent\", \".\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17dc22-ed77-429f-9287-7b44c54087c7",
   "metadata": {},
   "source": [
    "**training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b265881f-79bc-4aca-a973-e41a075e347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_loader = DataLoader(dataset=transformer_train_set, num_workers=0, batch_size=1, shuffle=False)\n",
    "val_set_loader = DataLoader(dataset=transformer_test_set, num_workers=0, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7f55774-f49f-4633-9d11-c89efa9e1a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13071/1085199502.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm(range(100)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d726bf2bbb44aea22029b72bd9a548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.27013, train_acc: 1.0000, val accuracy: 78.395\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 1.46884, train_acc: 0.5139, val accuracy: 78.858\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.39668, train_acc: 0.6667, val accuracy: 79.321\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.35783, train_acc: 0.7500, val accuracy: 79.090\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.38507, train_acc: 0.7889, val accuracy: 78.951\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.34106, train_acc: 0.8194, val accuracy: 78.755\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.40092, train_acc: 0.8413, val accuracy: 78.616\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.36208, train_acc: 0.8611, val accuracy: 78.472\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 0,  with loss: 0.32025, train_acc: 0.8735, val accuracy: 78.326\n",
      "AUC 1.0000\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.20372, train_acc: 1.0000, val accuracy: 77.469\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 1.86769, train_acc: 0.5139, val accuracy: 77.469\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.22385, train_acc: 0.6667, val accuracy: 77.469\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.21732, train_acc: 0.7500, val accuracy: 77.546\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.21078, train_acc: 0.8000, val accuracy: 77.593\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.17253, train_acc: 0.8333, val accuracy: 77.675\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.21816, train_acc: 0.8532, val accuracy: 77.690\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.20041, train_acc: 0.8715, val accuracy: 77.739\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 1,  with loss: 0.18687, train_acc: 0.8827, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.07863, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 2.56901, train_acc: 0.5139, val accuracy: 77.932\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.11155, train_acc: 0.6759, val accuracy: 77.984\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.11905, train_acc: 0.7569, val accuracy: 78.009\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.11047, train_acc: 0.8056, val accuracy: 78.025\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.08788, train_acc: 0.8380, val accuracy: 77.984\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.12859, train_acc: 0.8611, val accuracy: 77.954\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.11811, train_acc: 0.8785, val accuracy: 77.932\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 2,  with loss: 0.12167, train_acc: 0.8889, val accuracy: 77.949\n",
      "AUC 0.5000\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.05038, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 2.84759, train_acc: 0.5139, val accuracy: 77.932\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.07691, train_acc: 0.6759, val accuracy: 77.881\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.08360, train_acc: 0.7569, val accuracy: 77.932\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.07732, train_acc: 0.8056, val accuracy: 77.901\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.07352, train_acc: 0.8380, val accuracy: 77.881\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.11155, train_acc: 0.8611, val accuracy: 77.866\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.10179, train_acc: 0.8785, val accuracy: 77.855\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 3,  with loss: 0.11093, train_acc: 0.8889, val accuracy: 77.846\n",
      "AUC 1.0000\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.05334, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 2.42628, train_acc: 0.5139, val accuracy: 78.241\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.08778, train_acc: 0.6759, val accuracy: 79.527\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.09274, train_acc: 0.7569, val accuracy: 81.481\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.11605, train_acc: 0.8056, val accuracy: 82.901\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.09359, train_acc: 0.8380, val accuracy: 83.899\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.14687, train_acc: 0.8611, val accuracy: 84.568\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.13236, train_acc: 0.8785, val accuracy: 85.069\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 4,  with loss: 0.14532, train_acc: 0.8920, val accuracy: 85.460\n",
      "AUC 1.0000\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.13267, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 1.65611, train_acc: 0.5139, val accuracy: 88.580\n",
      "AUC 1.0000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.15194, train_acc: 0.6759, val accuracy: 88.580\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.18323, train_acc: 0.7569, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.15705, train_acc: 0.8056, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.12529, train_acc: 0.8380, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.17718, train_acc: 0.8611, val accuracy: 88.624\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.15989, train_acc: 0.8785, val accuracy: 88.619\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 5,  with loss: 0.15898, train_acc: 0.8920, val accuracy: 88.615\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.22080, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 1.24305, train_acc: 0.5139, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.15773, train_acc: 0.6759, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.15006, train_acc: 0.7569, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.11861, train_acc: 0.8056, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.08395, train_acc: 0.8380, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.11169, train_acc: 0.8611, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.09010, train_acc: 0.8785, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 6,  with loss: 0.09205, train_acc: 0.8920, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.12096, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 1.48309, train_acc: 0.5278, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.07494, train_acc: 0.6852, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.08187, train_acc: 0.7639, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.05966, train_acc: 0.8111, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.04496, train_acc: 0.8426, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.07773, train_acc: 0.8651, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.05972, train_acc: 0.8819, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 7,  with loss: 0.07894, train_acc: 0.8951, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.14095, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 1.15924, train_acc: 0.5417, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.07890, train_acc: 0.6944, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.07854, train_acc: 0.7708, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.07043, train_acc: 0.8167, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.04673, train_acc: 0.8472, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.07219, train_acc: 0.8690, val accuracy: 88.624\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.06095, train_acc: 0.8854, val accuracy: 88.619\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 8,  with loss: 0.07345, train_acc: 0.8981, val accuracy: 88.649\n",
      "AUC 0.7143\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.26071, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.73811, train_acc: 0.8056, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.05892, train_acc: 0.8704, val accuracy: 88.683\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.07037, train_acc: 0.9028, val accuracy: 88.735\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.04178, train_acc: 0.9222, val accuracy: 88.704\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.02162, train_acc: 0.9352, val accuracy: 88.683\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.04093, train_acc: 0.9444, val accuracy: 88.668\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.03815, train_acc: 0.9514, val accuracy: 88.696\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 9,  with loss: 0.05132, train_acc: 0.9568, val accuracy: 88.683\n",
      "AUC 0.7143\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.06385, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.80041, train_acc: 0.8194, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.03080, train_acc: 0.8796, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.05174, train_acc: 0.9097, val accuracy: 88.657\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.03297, train_acc: 0.9278, val accuracy: 88.704\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.01916, train_acc: 0.9398, val accuracy: 88.735\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.03859, train_acc: 0.9484, val accuracy: 88.757\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.04378, train_acc: 0.9549, val accuracy: 88.773\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 10,  with loss: 0.06487, train_acc: 0.9599, val accuracy: 88.786\n",
      "AUC 0.7143\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.22377, train_acc: 0.9722, val accuracy: 88.889\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.39890, train_acc: 0.9306, val accuracy: 88.735\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.02921, train_acc: 0.9537, val accuracy: 88.786\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.03806, train_acc: 0.9653, val accuracy: 88.812\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.01775, train_acc: 0.9722, val accuracy: 88.827\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.01012, train_acc: 0.9769, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.02033, train_acc: 0.9802, val accuracy: 88.757\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.02087, train_acc: 0.9826, val accuracy: 88.773\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 11,  with loss: 0.03056, train_acc: 0.9846, val accuracy: 88.752\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.01186, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.58646, train_acc: 0.9028, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.01446, train_acc: 0.9352, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.02867, train_acc: 0.9514, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.01975, train_acc: 0.9611, val accuracy: 88.827\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.01095, train_acc: 0.9676, val accuracy: 88.837\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.03210, train_acc: 0.9722, val accuracy: 88.801\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.03762, train_acc: 0.9757, val accuracy: 88.657\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 12,  with loss: 0.07513, train_acc: 0.9784, val accuracy: 88.409\n",
      "AUC 0.7143\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.20274, train_acc: 0.9722, val accuracy: 88.889\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.17529, train_acc: 0.9306, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.01821, train_acc: 0.9537, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.01831, train_acc: 0.9653, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.00969, train_acc: 0.9722, val accuracy: 88.827\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.00491, train_acc: 0.9769, val accuracy: 88.837\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.01137, train_acc: 0.9802, val accuracy: 88.845\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.01102, train_acc: 0.9826, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 13,  with loss: 0.01699, train_acc: 0.9846, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.00353, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 1.23023, train_acc: 0.5556, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.01093, train_acc: 0.7037, val accuracy: 88.477\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.04741, train_acc: 0.7778, val accuracy: 84.182\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.06676, train_acc: 0.8222, val accuracy: 80.000\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.09170, train_acc: 0.8519, val accuracy: 75.000\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.36705, train_acc: 0.8651, val accuracy: 72.002\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.26742, train_acc: 0.8819, val accuracy: 70.756\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 14,  with loss: 0.36115, train_acc: 0.8858, val accuracy: 70.988\n",
      "AUC 0.6429\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.71848, train_acc: 0.5556, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.22860, train_acc: 0.7222, val accuracy: 83.179\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.00256, train_acc: 0.8148, val accuracy: 81.379\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.00155, train_acc: 0.8611, val accuracy: 80.478\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.00079, train_acc: 0.8889, val accuracy: 79.938\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.00045, train_acc: 0.9074, val accuracy: 79.578\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.00077, train_acc: 0.9206, val accuracy: 79.321\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.00064, train_acc: 0.9306, val accuracy: 79.128\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 15,  with loss: 0.00078, train_acc: 0.9383, val accuracy: 78.978\n",
      "AUC 0.9286\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00020, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 11.98605, train_acc: 0.5000, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00039, train_acc: 0.6667, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00041, train_acc: 0.7500, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00038, train_acc: 0.8000, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00036, train_acc: 0.8333, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00082, train_acc: 0.8571, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00103, train_acc: 0.8750, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 16,  with loss: 0.00153, train_acc: 0.8889, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.00069, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 8.62053, train_acc: 0.5000, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.00174, train_acc: 0.6667, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.00288, train_acc: 0.7500, val accuracy: 77.778\n",
      "AUC 0.4286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.00354, train_acc: 0.8000, val accuracy: 77.778\n",
      "AUC 0.5000\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.00501, train_acc: 0.8333, val accuracy: 77.778\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.00978, train_acc: 0.8571, val accuracy: 77.778\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.01493, train_acc: 0.8750, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 17,  with loss: 0.02196, train_acc: 0.8889, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.01459, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 3.63654, train_acc: 0.5000, val accuracy: 77.778\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.04780, train_acc: 0.6667, val accuracy: 77.778\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.09103, train_acc: 0.7500, val accuracy: 77.855\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.15401, train_acc: 0.8000, val accuracy: 77.840\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.20767, train_acc: 0.8333, val accuracy: 77.778\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.28112, train_acc: 0.8532, val accuracy: 77.778\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.33864, train_acc: 0.8715, val accuracy: 77.816\n",
      "AUC 0.9286\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 18,  with loss: 0.32965, train_acc: 0.8858, val accuracy: 77.812\n",
      "AUC 0.9286\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.23930, train_acc: 1.0000, val accuracy: 78.086\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 1.15362, train_acc: 0.5139, val accuracy: 78.086\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.19756, train_acc: 0.6759, val accuracy: 78.086\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.22814, train_acc: 0.7569, val accuracy: 78.009\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.16970, train_acc: 0.8056, val accuracy: 77.963\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.12994, train_acc: 0.8380, val accuracy: 77.932\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.11978, train_acc: 0.8611, val accuracy: 77.910\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.09426, train_acc: 0.8785, val accuracy: 77.894\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 19,  with loss: 0.07588, train_acc: 0.8920, val accuracy: 77.881\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.05244, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 2.39481, train_acc: 0.5000, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.05482, train_acc: 0.6667, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.07266, train_acc: 0.7500, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.07570, train_acc: 0.8000, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.07531, train_acc: 0.8333, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.09168, train_acc: 0.8571, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.09533, train_acc: 0.8750, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 20,  with loss: 0.08685, train_acc: 0.8889, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.09656, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 1.56292, train_acc: 0.5000, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.10243, train_acc: 0.6667, val accuracy: 77.778\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.15193, train_acc: 0.7500, val accuracy: 77.855\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.14029, train_acc: 0.8000, val accuracy: 78.148\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.13594, train_acc: 0.8333, val accuracy: 78.498\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.13574, train_acc: 0.8571, val accuracy: 78.395\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.13001, train_acc: 0.8750, val accuracy: 78.318\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 21,  with loss: 0.11472, train_acc: 0.8889, val accuracy: 78.258\n",
      "AUC 0.5714\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.09850, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 1.39595, train_acc: 0.5000, val accuracy: 77.778\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.08068, train_acc: 0.6667, val accuracy: 77.778\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.11045, train_acc: 0.7500, val accuracy: 77.932\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.09291, train_acc: 0.8000, val accuracy: 78.025\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.07821, train_acc: 0.8333, val accuracy: 78.086\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.08781, train_acc: 0.8571, val accuracy: 78.042\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.07605, train_acc: 0.8750, val accuracy: 78.009\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 22,  with loss: 0.07963, train_acc: 0.8889, val accuracy: 77.984\n",
      "AUC 0.5714\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.08373, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 1.31440, train_acc: 0.5000, val accuracy: 77.932\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.07822, train_acc: 0.6667, val accuracy: 79.424\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.11581, train_acc: 0.7500, val accuracy: 80.941\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.10045, train_acc: 0.8000, val accuracy: 82.222\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.07923, train_acc: 0.8333, val accuracy: 82.973\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.09748, train_acc: 0.8571, val accuracy: 83.289\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.09188, train_acc: 0.8750, val accuracy: 83.295\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 23,  with loss: 0.08962, train_acc: 0.8889, val accuracy: 82.956\n",
      "AUC 0.5714\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.11093, train_acc: 1.0000, val accuracy: 77.778\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.93204, train_acc: 0.5556, val accuracy: 79.475\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.06518, train_acc: 0.7037, val accuracy: 81.893\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.08983, train_acc: 0.7778, val accuracy: 83.333\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.07245, train_acc: 0.8222, val accuracy: 84.259\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.05442, train_acc: 0.8519, val accuracy: 84.877\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.06686, train_acc: 0.8730, val accuracy: 85.273\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.05799, train_acc: 0.8889, val accuracy: 85.340\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 24,  with loss: 0.06742, train_acc: 0.9012, val accuracy: 85.322\n",
      "AUC 0.6429\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.08946, train_acc: 1.0000, val accuracy: 80.247\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.85786, train_acc: 0.6806, val accuracy: 83.333\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.04648, train_acc: 0.7870, val accuracy: 85.082\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.07574, train_acc: 0.8403, val accuracy: 85.957\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.05585, train_acc: 0.8722, val accuracy: 86.481\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.04785, train_acc: 0.8935, val accuracy: 86.831\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.05882, train_acc: 0.9087, val accuracy: 87.081\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.06079, train_acc: 0.9201, val accuracy: 87.269\n",
      "AUC 0.5714\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 25,  with loss: 0.07092, train_acc: 0.9290, val accuracy: 87.414\n",
      "AUC 0.5714\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.12537, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.52964, train_acc: 0.9444, val accuracy: 88.580\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.04674, train_acc: 0.9630, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.05795, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.03801, train_acc: 0.9778, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.02500, train_acc: 0.9815, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.03344, train_acc: 0.9841, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.03305, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 26,  with loss: 0.03986, train_acc: 0.9877, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.06950, train_acc: 1.0000, val accuracy: 88.272\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.52949, train_acc: 0.9306, val accuracy: 88.426\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.03175, train_acc: 0.9537, val accuracy: 88.477\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.04291, train_acc: 0.9653, val accuracy: 88.503\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.02466, train_acc: 0.9722, val accuracy: 88.519\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.02121, train_acc: 0.9769, val accuracy: 88.529\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.03202, train_acc: 0.9802, val accuracy: 88.536\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.03488, train_acc: 0.9826, val accuracy: 88.542\n",
      "AUC 0.6429\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 27,  with loss: 0.04616, train_acc: 0.9846, val accuracy: 88.546\n",
      "AUC 0.6429\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.10029, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.32858, train_acc: 0.9444, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.02878, train_acc: 0.9630, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.03677, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.02024, train_acc: 0.9778, val accuracy: 88.580\n",
      "AUC 0.7143\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.01608, train_acc: 0.9815, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.02196, train_acc: 0.9841, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.02163, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 28,  with loss: 0.02929, train_acc: 0.9877, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.05112, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.29309, train_acc: 0.9444, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.02171, train_acc: 0.9630, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.02914, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.01437, train_acc: 0.9778, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.01072, train_acc: 0.9815, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.01909, train_acc: 0.9841, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.02083, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 29,  with loss: 0.03096, train_acc: 0.9877, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.05710, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.20220, train_acc: 0.9583, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.01855, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.02327, train_acc: 0.9792, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.01236, train_acc: 0.9833, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.00846, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.01462, train_acc: 0.9881, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.01605, train_acc: 0.9896, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 30,  with loss: 0.02761, train_acc: 0.9907, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.03661, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.16339, train_acc: 0.9583, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.01254, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.01742, train_acc: 0.9792, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.00890, train_acc: 0.9833, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.00663, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.01424, train_acc: 0.9881, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.01261, train_acc: 0.9896, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 31,  with loss: 0.02515, train_acc: 0.9907, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.02974, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.15487, train_acc: 0.9583, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.01338, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.01675, train_acc: 0.9792, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.00767, train_acc: 0.9833, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.00582, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.01151, train_acc: 0.9881, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.01288, train_acc: 0.9896, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 32,  with loss: 0.02262, train_acc: 0.9907, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.02854, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.10644, train_acc: 0.9722, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.01211, train_acc: 0.9815, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.01459, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.00758, train_acc: 0.9889, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.00505, train_acc: 0.9907, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.01061, train_acc: 0.9921, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.01105, train_acc: 0.9931, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 33,  with loss: 0.01957, train_acc: 0.9938, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.02095, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.10393, train_acc: 0.9861, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.00797, train_acc: 0.9907, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.01246, train_acc: 0.9931, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.00527, train_acc: 0.9944, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.00421, train_acc: 0.9954, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.00935, train_acc: 0.9960, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.01045, train_acc: 0.9965, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 34,  with loss: 0.01842, train_acc: 0.9969, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.02797, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.10797, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.00733, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.00892, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.00476, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.00362, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.00847, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.00915, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 35,  with loss: 0.01679, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.02131, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.07498, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.00710, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.01035, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.00424, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.00360, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.00750, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.00945, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 36,  with loss: 0.01656, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.01695, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.07806, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.00543, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.00897, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.00431, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.00299, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.00867, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.00859, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 37,  with loss: 0.01638, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.01407, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.05492, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.00522, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.00733, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.00416, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.00239, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.00490, train_acc: 1.0000, val accuracy: 88.624\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.00658, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 38,  with loss: 0.01381, train_acc: 1.0000, val accuracy: 88.615\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.01328, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.05737, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.00466, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.00736, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.00333, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.00210, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.00540, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.00713, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 39,  with loss: 0.01226, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.01404, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.04945, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.00523, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.00672, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.00280, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.00200, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.00483, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.00633, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 40,  with loss: 0.01018, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.01219, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.04429, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.00378, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.00525, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.00319, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.00178, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.00500, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.00559, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 41,  with loss: 0.01013, train_acc: 1.0000, val accuracy: 88.615\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00841, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.04533, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00388, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00574, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00226, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00156, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00346, train_acc: 1.0000, val accuracy: 88.624\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00495, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 42,  with loss: 0.00924, train_acc: 1.0000, val accuracy: 88.615\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.01149, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.04454, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.00368, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.00446, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.00236, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.00147, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.00378, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.00523, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 43,  with loss: 0.00941, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00749, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.03332, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00303, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00495, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00205, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00135, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00360, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00453, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 44,  with loss: 0.00989, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00800, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.03094, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00301, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00471, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00198, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00113, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00347, train_acc: 1.0000, val accuracy: 88.624\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00401, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 45,  with loss: 0.00879, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00730, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.02768, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00214, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00461, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00165, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00102, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00290, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00471, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 46,  with loss: 0.00890, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00783, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.03241, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00229, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00367, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00159, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00107, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00247, train_acc: 1.0000, val accuracy: 88.624\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00397, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 47,  with loss: 0.00985, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.01048, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.02932, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.00212, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.00336, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.00165, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.00094, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.00231, train_acc: 1.0000, val accuracy: 88.624\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.00323, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 48,  with loss: 0.00669, train_acc: 1.0000, val accuracy: 88.615\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00511, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.02639, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00219, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00326, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00117, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00107, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00244, train_acc: 1.0000, val accuracy: 88.624\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00375, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 49,  with loss: 0.00616, train_acc: 1.0000, val accuracy: 88.615\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00749, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.02423, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00189, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00386, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00130, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00091, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00270, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00319, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 50,  with loss: 0.00601, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00541, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.02107, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00187, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00270, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00109, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00088, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00260, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00280, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 51,  with loss: 0.00631, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00558, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.02152, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00157, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00257, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00126, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00074, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00200, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00255, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 52,  with loss: 0.00540, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00383, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.02584, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00147, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00260, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00126, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00080, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00203, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00297, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 53,  with loss: 0.00550, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00368, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.02157, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00172, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00255, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00108, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00077, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00180, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00246, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 54,  with loss: 0.00544, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00585, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.02136, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00177, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00293, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00111, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00073, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00217, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00286, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 55,  with loss: 0.00579, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00855, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.01577, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00174, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00236, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00084, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00062, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00168, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00233, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 56,  with loss: 0.00462, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00413, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.01793, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00154, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00227, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00083, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00060, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00171, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00271, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 57,  with loss: 0.00470, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00322, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.01914, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00126, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00223, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00106, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00055, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00155, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00235, train_acc: 1.0000, val accuracy: 88.619\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 58,  with loss: 0.00518, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00459, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.01744, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00124, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00234, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00078, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00058, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00161, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00236, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 59,  with loss: 0.00489, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00367, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.01663, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00128, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00220, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00076, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00058, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00158, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00186, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 60,  with loss: 0.00491, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00407, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.01770, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00127, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00228, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00072, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00047, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00154, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00196, train_acc: 1.0000, val accuracy: 88.773\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 61,  with loss: 0.00413, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00298, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.01433, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00131, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00215, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00072, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00057, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00145, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00194, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 62,  with loss: 0.00466, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00471, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.01469, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00130, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00176, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00088, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00052, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00120, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00177, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 63,  with loss: 0.00378, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00357, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.01182, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00121, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00174, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00064, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00049, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00139, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00192, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 64,  with loss: 0.00360, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00245, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.01258, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00088, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00165, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00075, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00043, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00173, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00178, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 65,  with loss: 0.00356, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00347, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.01547, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00088, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00191, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00060, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00044, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00154, train_acc: 1.0000, val accuracy: 88.713\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00205, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 66,  with loss: 0.00339, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00306, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.01286, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00097, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00179, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00079, train_acc: 1.0000, val accuracy: 88.642\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00047, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00131, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00172, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 67,  with loss: 0.00403, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00289, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.01208, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00103, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00171, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00075, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00039, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00151, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00198, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 68,  with loss: 0.00333, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00219, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.01324, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00098, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00154, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00058, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00038, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00123, train_acc: 1.0000, val accuracy: 88.845\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00170, train_acc: 1.0000, val accuracy: 88.850\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 69,  with loss: 0.00395, train_acc: 1.0000, val accuracy: 88.855\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00280, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.01110, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00101, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00160, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00062, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00040, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00122, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00187, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 70,  with loss: 0.00376, train_acc: 1.0000, val accuracy: 88.649\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00189, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.01142, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00079, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00160, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00061, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00041, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00106, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00159, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 71,  with loss: 0.00290, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00274, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.01385, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00076, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00148, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00072, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00042, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00106, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00152, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 72,  with loss: 0.00320, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00236, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.01196, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00110, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00150, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00067, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00030, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00105, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00169, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 73,  with loss: 0.00297, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00234, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.01194, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00102, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00165, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00043, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00109, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00134, train_acc: 1.0000, val accuracy: 88.773\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 74,  with loss: 0.00342, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00353, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00943, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00086, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00145, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00067, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00034, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00104, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00164, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 75,  with loss: 0.00334, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00270, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00850, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00097, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00130, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00050, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00034, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00103, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00144, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 76,  with loss: 0.00321, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00197, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.01022, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00087, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00134, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00063, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00099, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00138, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 77,  with loss: 0.00278, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00350, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.01056, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00067, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00144, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00047, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00113, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00132, train_acc: 1.0000, val accuracy: 88.773\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 78,  with loss: 0.00290, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00198, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00932, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00092, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00133, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00054, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00035, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00106, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00155, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 79,  with loss: 0.00301, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00259, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.01123, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00081, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00146, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00053, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00106, train_acc: 1.0000, val accuracy: 88.845\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00180, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 80,  with loss: 0.00275, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00282, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00977, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00076, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00160, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00054, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00097, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00135, train_acc: 1.0000, val accuracy: 88.773\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 81,  with loss: 0.00251, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00134, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00806, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00078, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00132, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00051, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00027, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00104, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00133, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 82,  with loss: 0.00329, train_acc: 1.0000, val accuracy: 88.752\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00254, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00991, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00074, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00116, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00042, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00102, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00123, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 83,  with loss: 0.00314, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00269, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.01079, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00067, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00121, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00055, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00030, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00094, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00139, train_acc: 1.0000, val accuracy: 88.773\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 84,  with loss: 0.00303, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00274, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00821, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00071, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00146, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00050, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00028, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00106, train_acc: 1.0000, val accuracy: 88.845\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00125, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 85,  with loss: 0.00289, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00280, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00910, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00104, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00115, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00042, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00099, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00123, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 86,  with loss: 0.00301, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00467, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00766, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00059, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00118, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00048, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00030, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00085, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00130, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 87,  with loss: 0.00244, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00290, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.01068, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00061, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00120, train_acc: 1.0000, val accuracy: 88.657\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00044, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00037, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00092, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00130, train_acc: 1.0000, val accuracy: 88.773\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 88,  with loss: 0.00247, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00205, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.01049, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00076, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00105, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00044, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00026, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00107, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00137, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 89,  with loss: 0.00236, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00391, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00949, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00086, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00104, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00049, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00028, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00094, train_acc: 1.0000, val accuracy: 88.845\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00123, train_acc: 1.0000, val accuracy: 88.850\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 90,  with loss: 0.00262, train_acc: 1.0000, val accuracy: 88.855\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00221, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00926, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00065, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00127, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00046, train_acc: 1.0000, val accuracy: 88.704\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00094, train_acc: 1.0000, val accuracy: 88.757\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00142, train_acc: 1.0000, val accuracy: 88.773\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 91,  with loss: 0.00290, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00229, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.01087, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00071, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00112, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00046, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00026, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00122, train_acc: 1.0000, val accuracy: 88.845\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00142, train_acc: 1.0000, val accuracy: 88.850\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 92,  with loss: 0.00235, train_acc: 1.0000, val accuracy: 88.855\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00205, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.01189, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00073, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00120, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00046, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00030, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00113, train_acc: 1.0000, val accuracy: 88.845\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00122, train_acc: 1.0000, val accuracy: 88.850\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 93,  with loss: 0.00250, train_acc: 1.0000, val accuracy: 88.855\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00193, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00932, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00080, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00116, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00050, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00027, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00108, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00120, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 94,  with loss: 0.00282, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00215, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.01046, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00067, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00106, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00044, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00034, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00079, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00142, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 95,  with loss: 0.00329, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00248, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00911, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00077, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00116, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00046, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00028, train_acc: 1.0000, val accuracy: 88.837\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00094, train_acc: 1.0000, val accuracy: 88.845\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00149, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 96,  with loss: 0.00250, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00241, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.01057, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00092, train_acc: 1.0000, val accuracy: 88.683\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00120, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00048, train_acc: 1.0000, val accuracy: 88.765\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00025, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00100, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00146, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 97,  with loss: 0.00218, train_acc: 1.0000, val accuracy: 88.820\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00189, train_acc: 1.0000, val accuracy: 88.889\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00822, train_acc: 1.0000, val accuracy: 88.735\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00065, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00121, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00046, train_acc: 1.0000, val accuracy: 88.827\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00029, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00094, train_acc: 1.0000, val accuracy: 88.801\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00126, train_acc: 1.0000, val accuracy: 88.812\n",
      "AUC 0.8571\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 98,  with loss: 0.00233, train_acc: 1.0000, val accuracy: 88.786\n",
      "AUC 0.8571\n",
      "DONE at batch number: 9 and ending now\n",
      "num iterations of train: 1908\n",
      "in train: torch.Size([1, 36, 358]) torch.Size([36]) torch.Size([36])\n",
      "batch index 0, 0/1 distribution: 36/0\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00184, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00954, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00072, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00114, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00053, train_acc: 1.0000, val accuracy: 88.580\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00032, train_acc: 1.0000, val accuracy: 88.632\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00092, train_acc: 1.0000, val accuracy: 88.668\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00128, train_acc: 1.0000, val accuracy: 88.696\n",
      "AUC 0.7857\n",
      "num iterations of val: 1908\n",
      "val DONE at batch number: 9 and ending now\n",
      "epoch: 99,  with loss: 0.00261, train_acc: 1.0000, val accuracy: 88.717\n",
      "AUC 0.7857\n",
      "DONE at batch number: 9 and ending now\n"
     ]
    }
   ],
   "source": [
    "#START TRAINING!\n",
    "numpatsval = 10\n",
    "numpatstrain = 10\n",
    "for epoch in tqdm(range(100)):\n",
    "    #DOING THIS BY EPOCH FOR AUROC\n",
    "    transall_labels = []\n",
    "    all_probs_ones = []\n",
    "    transall_patients = []\n",
    "    train_transall_patients = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    traincorrect = 0\n",
    "    traintotal = 0\n",
    "    valcount = 0.0\n",
    "    traincount = 0.0\n",
    "\n",
    "    \n",
    "#        UPDATE LEARNING RATE ONCE PER EPOCH\n",
    "    if(epoch > 0):\n",
    "        scheduler.step()\n",
    "\n",
    "     #this calls getitem (for each i in train_set_loader)\n",
    "    print(\"num iterations of train:\", len(train_set_loader))\n",
    "    model.train() #train mode\n",
    "    for i, data in enumerate(train_set_loader):\n",
    "        \n",
    "        if(i >= (numpatstrain-1)):\n",
    "            print(\"DONE at batch number:\", i, \"and ending now\")\n",
    "            break\n",
    "\n",
    "        inputs = data['input'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        annot_ids = data['annot_id']\n",
    "        framenums = data['framenum']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #get batch size out of all\n",
    "        labels = labels.squeeze(0)\n",
    "        annot_ids = annot_ids.squeeze(0)\n",
    "        \n",
    "        train_transall_patients = np.append(train_transall_patients, annot_ids[0])\n",
    "        if (i % 100 == 0):\n",
    "            print(\"in train:\", inputs.shape, labels.shape, annot_ids.shape)\n",
    "            print(\"batch index {}, 0/1 distribution: {}/{}\".format(i, len(np.where(labels.cpu().numpy() == 0)[0]),\n",
    "        len(np.where(labels.cpu().numpy() == 1)[0])))\n",
    "            \n",
    "        # forward + backward + optimize (to find good parameters: weights + bias)\n",
    "        outputs = model(inputs).to(device)\n",
    "        #now squeeze outt he 1 from the outputs shape [x, 1, 2]\n",
    "        outputs = outputs.squeeze(1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        traincount += 1.0\n",
    "        \n",
    "\n",
    "        sf = nn.Softmax(dim=1) #makes items in a row add to 1; dim = 0 makes items in a column add to 1\n",
    "        outputs = sf(outputs)\n",
    "        _, trainpredicted = torch.max(outputs, 1)\n",
    "\n",
    "        traincorrect += (trainpredicted.cpu() == labels.cpu()).sum()\n",
    "\n",
    "\n",
    "        # Total number of labels\n",
    "        try:\n",
    "            traintotal += len(labels.cpu())\n",
    "        except:\n",
    "            print(i, \"index len 0 trainlabels; input shape\", np.shape(inputs.cpu().numpy()))\n",
    "\n",
    "        trainaccuracy = traincorrect / traintotal\n",
    "\n",
    "        model.train()\n",
    "        #calculate val accuracy\n",
    "\n",
    "        with torch.no_grad():\n",
    "            print(\"num iterations of val:\", len(val_set_loader))\n",
    "            for j, dataa in enumerate(val_set_loader):\n",
    "\n",
    "                if(j >= (numpatsval-1)):\n",
    "                    print(\"val DONE at batch number:\", j, \"and ending now\")\n",
    "                    break\n",
    "\n",
    "                tinputs = dataa['input'].to(device)\n",
    "                tlabels = dataa['label'].to(device)\n",
    "                tannot_ids = dataa['annot_id']\n",
    "\n",
    "                tlabels = tlabels.squeeze(0)\n",
    "                tannot_ids = tannot_ids.squeeze(0)\n",
    "    \n",
    "                # Forward pass only to get logits/output\n",
    "                outs = model(tinputs)\n",
    "                outs = outs.squeeze(1)\n",
    "\n",
    "\n",
    "                sf = nn.Softmax(dim=1) #makes items in a row add to 1; dim = 0 makes items in a column add to 1\n",
    "                outs = sf(outs)\n",
    "\n",
    "                _, predicted = torch.max(outs, 1)\n",
    "\n",
    "                outs_ones = outs.detach().cpu().numpy()[:, 1]\n",
    "                tlabelsnp = tlabels.cpu().numpy()\n",
    "                transall_labels = np.append(transall_labels, tlabelsnp)\n",
    "                \n",
    "                if(j%100 == 0 or (tlabelsnp[0] == \"1\" and j%20 == 0)):\n",
    "                    if(np.isnan(outs.detach().cpu().numpy()).any()):\n",
    "                        print(\"val inputs:\", tinputs.detach().cpu().numpy())\n",
    "                        print(\"val outputs:\", outs.detach().cpu().numpy(), outs_ones, \"vs. labels:\", tlabelsnp)\n",
    "                    \n",
    "\n",
    "\n",
    "                all_probs_ones = np.append(all_probs_ones, outs_ones)\n",
    "\n",
    "                tannot_ids = np.asarray(tannot_ids)\n",
    "                transall_patients = np.append(transall_patients, tannot_ids)\n",
    "\n",
    "                #  USE GPU FOR MODEL\n",
    "                # Total correct predictions\n",
    "\n",
    "                correct += (predicted.cpu() == tlabels.cpu()).sum()\n",
    "                total += len(tlabels.cpu())\n",
    "\n",
    "                #end of torch no grad\n",
    "                accuracy = 100 * correct / total\n",
    "\n",
    "            \n",
    "            #print statistics\n",
    "            message = 'epoch: %d,  with loss: %.5f, train_acc: %.4f, val accuracy: %.3f' % (\n",
    "                epoch, loss, trainaccuracy.data, accuracy.data)\n",
    "            print(message)\n",
    "            \n",
    "        patients = [] #distinct patients\n",
    "        for p in range(len(transall_patients)):\n",
    "            if not (transall_patients[p] in patients):\n",
    "                patients.append(transall_patients[p])\n",
    "\n",
    "        patient_ave_preds = []\n",
    "        patientlabels = []\n",
    "        count = 0\n",
    "        sum_pat_pred = 0\n",
    "        cur_pat_labels = []\n",
    "        patientwise_auroc = 0\n",
    "\n",
    "        while(count < len(patients)):\n",
    "            for p in range(len(transall_patients)):\n",
    "                if (transall_patients[p] == patients[count]): #one patient at a time\n",
    "                    sum_pat_pred += all_probs_ones[p]\n",
    "                    cur_pat_label = transall_labels[p]\n",
    "                    cur_pat_labels.append(transall_labels[p])\n",
    "            patient_ave_preds.append(sum_pat_pred / float(len(cur_pat_labels)))\n",
    "            patientlabels.append(cur_pat_labels[0])\n",
    "            \n",
    "            count += 1\n",
    "            cur_pat_labels = []\n",
    "            sum_pat_pred = 0\n",
    "        patientwise_auroc = roc_auc_score(patientlabels, patient_ave_preds)\n",
    "        print(\"AUC %.4f\" % patientwise_auroc)\n",
    "        model.train() #back to train mode, end of validation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb262ba-9582-4e71-8ba1-bd01924c6a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "replicate_thyroid",
   "language": "python",
   "name": "replicate_thyroid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
